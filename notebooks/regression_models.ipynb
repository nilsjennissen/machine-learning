{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nilsjennissen/machine-learning/blob/main/notebooks/regression_models.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression Models in Practice\n",
    "### Predicting used car prices with the best model possible"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Business Objective:** We have been hired by a used car dealer (Cars Cars Cars) to create a pricing model they can use in their operations. They have provided as a file (attached) with car prices and several features we can use to create a model to predict these prices.\n",
    "car data.csv Download car data.csv\n",
    "The dependent variable is column \"selling price\" in the file. \"Present price\" describes the current price of the car if we were going to buy it new. The rest of the columns are self explanatory.\n",
    "\n",
    "Your job is to use all regression and data preparation techniques you know to create the best model for our customer.\n",
    "\n",
    "You have to deliver a visually appealing notebook that explores all alternatives, describes all relevant steps and presents conclusions in a clear way. We have been hired by Cars Cars Cars CTO, and eventhough she has basic knowledge about regression techniques and a technical background she might need some context in some of the steps to fully understand our deliverable.\n",
    "\n",
    "Of course after presenting the different alternatives with its performance metrics we have to describe the one that is obtaining the best results.\n",
    "\n",
    "This is the first work we do for this customer and we want to create a great impression so we can become their data science partners for the rest of their projects, so use all you've got to create a great model with a performance better than the competition!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Project Outline**\n",
    "#### **1. Data Explorartion**\n",
    "#### **2. Data Preprocessing**\n",
    "* **2.1 Data Cleaning**\n",
    "* **2.2 Summary Report**\n",
    "* **2.3 Model Functions**\n",
    "#### **3. Model Comparison**\n",
    "* **3.1 Linear Regression**\n",
    "* **3.2  Support Vector Machines**\n",
    "* **3.3 Linear SVR**\n",
    "* **3.4 MLP Regressor**\n",
    "* **3.5 Decision Tree Regressor**\n",
    "* **3.6 Stochastic Gradient Descent**\n",
    "* **3.7 Random Forest with GridSearchCV**\n",
    "* **3.8 XGB**\n",
    "* **3.9 LGBM**\n",
    "* **3.10 GradientBoostingRegressor with HyperOpt**\n",
    "* **3.11 RidgeRegressor**\n",
    "* **3.12 BaggingRegressor**\n",
    "* **3.13 ExtraTreesRegressor**\n",
    "* **3.14 AdaBoostRegressor**\n",
    "* **3.15 VotingRegressor**\n",
    "#### **4. Model Selection**\n",
    "#### **5. Prediction**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "import ydata_profiling as pp\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, RidgeCV\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, VotingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import cross_val_predict as cvp\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Model tuning\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n",
    "\n",
    "# Error handling\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:20:54.621062Z",
     "start_time": "2023-05-24T13:20:54.591097Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **1. Data Exploration**\n",
    "\n",
    "In the first step we will explore the data and get a better understanding of the data. We will look at the data types, missing values, and the distribution of the data. We will also look at the correlation between the variables and the target variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  Car_Name  Year  Selling_Price  Present_Price  Kms_Driven Fuel_Type   \n0     ritz  2014           3.35           5.59       27000    Petrol  \\\n1      sx4  2013           4.75           9.54       43000    Diesel   \n2     ciaz  2017           7.25           9.85        6900    Petrol   \n3  wagon r  2011           2.85           4.15        5200    Petrol   \n4    swift  2014           4.60           6.87       42450    Diesel   \n\n  Seller_Type Transmission  Owner  \n0      Dealer       Manual      0  \n1      Dealer       Manual      0  \n2      Dealer       Manual      0  \n3      Dealer       Manual      0  \n4      Dealer       Manual      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Car_Name</th>\n      <th>Year</th>\n      <th>Selling_Price</th>\n      <th>Present_Price</th>\n      <th>Kms_Driven</th>\n      <th>Fuel_Type</th>\n      <th>Seller_Type</th>\n      <th>Transmission</th>\n      <th>Owner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ritz</td>\n      <td>2014</td>\n      <td>3.35</td>\n      <td>5.59</td>\n      <td>27000</td>\n      <td>Petrol</td>\n      <td>Dealer</td>\n      <td>Manual</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sx4</td>\n      <td>2013</td>\n      <td>4.75</td>\n      <td>9.54</td>\n      <td>43000</td>\n      <td>Diesel</td>\n      <td>Dealer</td>\n      <td>Manual</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ciaz</td>\n      <td>2017</td>\n      <td>7.25</td>\n      <td>9.85</td>\n      <td>6900</td>\n      <td>Petrol</td>\n      <td>Dealer</td>\n      <td>Manual</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>wagon r</td>\n      <td>2011</td>\n      <td>2.85</td>\n      <td>4.15</td>\n      <td>5200</td>\n      <td>Petrol</td>\n      <td>Dealer</td>\n      <td>Manual</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>swift</td>\n      <td>2014</td>\n      <td>4.60</td>\n      <td>6.87</td>\n      <td>42450</td>\n      <td>Diesel</td>\n      <td>Dealer</td>\n      <td>Manual</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train0 = pd.read_csv('../data/car_data.csv')\n",
    "train0.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:20:56.441743Z",
     "start_time": "2023-05-24T13:20:56.408698Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "dimensions": [
          {
           "axis": {
            "matches": true
           },
           "label": "Present_Price",
           "values": [
            5.59,
            9.54,
            9.85,
            4.15,
            6.87,
            9.83,
            8.12,
            8.61,
            8.89,
            8.92,
            3.6,
            10.38,
            9.94,
            7.71,
            7.21,
            10.79,
            10.79,
            10.79,
            5.09,
            7.98,
            3.95,
            5.71,
            8.01,
            3.46,
            4.41,
            4.99,
            5.87,
            6.49,
            3.95,
            10.38,
            5.98,
            4.89,
            7.49,
            9.95,
            8.06,
            7.74,
            7.2,
            2.28,
            3.76,
            7.98,
            7.87,
            3.98,
            7.15,
            8.06,
            2.69,
            12.04,
            4.89,
            4.15,
            7.71,
            9.29,
            30.61,
            30.61,
            19.77,
            30.61,
            10.21,
            15.04,
            7.27,
            18.54,
            6.8,
            35.96,
            18.61,
            7.7,
            35.96,
            35.96,
            36.23,
            6.95,
            23.15,
            20.45,
            13.74,
            20.91,
            6.76,
            12.48,
            18.61,
            5.71,
            8.93,
            6.8,
            14.68,
            12.35,
            22.83,
            30.61,
            14.89,
            7.85,
            25.39,
            13.46,
            13.46,
            23.73,
            92.6,
            13.74,
            6.05,
            6.76,
            18.61,
            16.09,
            13.7,
            30.61,
            22.78,
            18.61,
            25.39,
            18.64,
            18.61,
            20.45,
            1.9,
            1.82,
            1.78,
            1.6,
            1.47,
            2.37,
            3.45,
            1.5,
            1.5,
            1.47,
            1.78,
            1.5,
            2.4,
            1.4,
            1.47,
            1.47,
            1.47,
            1.9,
            1.47,
            1.9,
            1.26,
            1.5,
            1.17,
            1.47,
            1.75,
            1.75,
            0.95,
            0.8,
            0.87,
            0.84,
            0.87,
            0.82,
            0.95,
            0.95,
            0.81,
            0.74,
            1.2,
            0.787,
            0.87,
            0.95,
            1.2,
            0.8,
            0.84,
            0.84,
            0.99,
            0.81,
            0.787,
            0.84,
            0.94,
            0.94,
            0.826,
            0.55,
            0.99,
            0.99,
            0.88,
            0.51,
            0.52,
            0.84,
            0.54,
            0.51,
            0.95,
            0.826,
            0.99,
            0.95,
            0.54,
            0.54,
            0.55,
            0.81,
            0.73,
            0.54,
            0.83,
            0.55,
            0.64,
            0.51,
            0.72,
            0.787,
            1.05,
            0.57,
            0.52,
            1.05,
            0.51,
            0.48,
            0.58,
            0.47,
            0.75,
            0.58,
            0.52,
            0.51,
            0.57,
            0.57,
            0.75,
            0.57,
            0.75,
            0.65,
            0.787,
            0.32,
            0.52,
            0.51,
            0.57,
            0.58,
            0.75,
            6.79,
            5.7,
            4.6,
            4.43,
            5.7,
            7.13,
            5.7,
            8.1,
            5.7,
            4.6,
            14.79,
            13.6,
            6.79,
            5.7,
            9.4,
            4.43,
            4.43,
            9.4,
            9.4,
            4.43,
            6.79,
            7.6,
            9.4,
            9.4,
            4.6,
            5.7,
            4.43,
            9.4,
            6.79,
            9.4,
            9.4,
            14.79,
            5.7,
            5.7,
            9.4,
            4.43,
            13.6,
            9.4,
            4.43,
            9.4,
            7.13,
            7.13,
            7.6,
            9.4,
            9.4,
            6.79,
            9.4,
            4.6,
            7.6,
            13.6,
            9.9,
            6.82,
            9.9,
            9.9,
            5.35,
            13.6,
            13.6,
            13.6,
            7.0,
            13.6,
            5.97,
            5.8,
            7.7,
            7.0,
            8.7,
            7.0,
            9.4,
            5.8,
            10.0,
            10.0,
            10.0,
            10.0,
            7.5,
            6.8,
            13.6,
            13.6,
            13.6,
            8.4,
            13.6,
            5.9,
            7.6,
            14.0,
            11.8,
            5.9,
            8.5,
            7.9,
            7.5,
            13.6,
            13.6,
            6.4,
            6.1,
            8.4,
            9.9,
            6.8,
            13.09,
            11.6,
            5.9,
            11.0,
            12.5,
            5.9
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "Kms_Driven",
           "values": [
            27000,
            43000,
            6900,
            5200,
            42450,
            2071,
            18796,
            33429,
            20273,
            42367,
            2135,
            51000,
            15000,
            26000,
            77427,
            43000,
            41678,
            43000,
            35500,
            41442,
            25000,
            2400,
            50000,
            45280,
            56879,
            20000,
            55138,
            16200,
            44542,
            45000,
            51439,
            54200,
            39000,
            45000,
            45000,
            49998,
            48767,
            127000,
            10079,
            62000,
            24524,
            46706,
            58000,
            45780,
            50000,
            15000,
            64532,
            65000,
            25870,
            37000,
            104707,
            40000,
            15000,
            135000,
            90000,
            70000,
            40534,
            50000,
            39485,
            41000,
            40001,
            40588,
            78000,
            47000,
            6000,
            45000,
            11000,
            59000,
            88000,
            12000,
            71000,
            45000,
            56001,
            43000,
            83000,
            36000,
            72000,
            135154,
            80000,
            89000,
            23000,
            40000,
            15000,
            38000,
            197176,
            142000,
            78000,
            56000,
            47000,
            40000,
            62000,
            58242,
            75000,
            40000,
            89000,
            72000,
            29000,
            8700,
            45000,
            50024,
            3000,
            1400,
            4000,
            1200,
            4100,
            21700,
            16500,
            15000,
            18000,
            11000,
            6000,
            8700,
            7000,
            35000,
            17000,
            17500,
            33000,
            14000,
            26000,
            5400,
            5700,
            6900,
            6000,
            46500,
            11500,
            40000,
            1300,
            7000,
            3000,
            5000,
            11000,
            18000,
            3500,
            500,
            11800,
            5000,
            23500,
            16000,
            15000,
            16600,
            32000,
            20000,
            29000,
            25000,
            25000,
            19000,
            15000,
            58000,
            45000,
            24000,
            6000,
            31000,
            13000,
            45000,
            8000,
            4300,
            15000,
            23000,
            8600,
            4000,
            24000,
            23000,
            14500,
            27000,
            14000,
            500,
            1000,
            42000,
            12000,
            14000,
            5500,
            6700,
            13700,
            1300,
            38600,
            75000,
            30000,
            24000,
            19000,
            213000,
            60000,
            50000,
            30000,
            21000,
            26000,
            1900,
            22000,
            32000,
            18000,
            55000,
            60000,
            25000,
            49000,
            24000,
            50000,
            35000,
            500000,
            33000,
            35000,
            53000,
            92233,
            58000,
            28200,
            53460,
            28282,
            3493,
            12479,
            34797,
            3435,
            21125,
            35775,
            43535,
            22671,
            31604,
            20114,
            36100,
            12500,
            15000,
            45078,
            36000,
            38488,
            32000,
            77632,
            61381,
            36198,
            22517,
            24678,
            57000,
            60000,
            52132,
            45000,
            15001,
            12900,
            53000,
            4492,
            15141,
            11849,
            68000,
            60241,
            23709,
            32322,
            35866,
            34000,
            7000,
            49000,
            71000,
            35000,
            36000,
            30000,
            17000,
            35934,
            56701,
            31427,
            48000,
            54242,
            53675,
            49562,
            40324,
            25000,
            36054,
            29223,
            5600,
            40023,
            16002,
            40026,
            21200,
            35000,
            19434,
            19000,
            18828,
            69341,
            69562,
            27600,
            61203,
            16500,
            30753,
            24800,
            21780,
            4000,
            40126,
            14465,
            50456,
            63000,
            9010,
            9800,
            15059,
            28569,
            44000,
            34000,
            10980,
            19000,
            31427,
            12000,
            38000,
            33019,
            60076,
            33988,
            60000,
            87934,
            9000,
            5464
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "Owner",
           "values": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            3,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            1,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "Year",
           "values": [
            2014,
            2013,
            2017,
            2011,
            2014,
            2018,
            2015,
            2015,
            2016,
            2015,
            2017,
            2015,
            2015,
            2015,
            2009,
            2016,
            2015,
            2016,
            2015,
            2010,
            2016,
            2017,
            2011,
            2014,
            2013,
            2011,
            2013,
            2017,
            2010,
            2015,
            2012,
            2011,
            2014,
            2014,
            2014,
            2011,
            2015,
            2003,
            2016,
            2003,
            2016,
            2014,
            2008,
            2014,
            2012,
            2014,
            2013,
            2006,
            2015,
            2017,
            2012,
            2015,
            2017,
            2013,
            2005,
            2009,
            2015,
            2010,
            2014,
            2014,
            2013,
            2015,
            2014,
            2015,
            2017,
            2014,
            2017,
            2010,
            2011,
            2016,
            2014,
            2011,
            2013,
            2011,
            2014,
            2015,
            2013,
            2004,
            2010,
            2012,
            2016,
            2015,
            2017,
            2015,
            2005,
            2006,
            2010,
            2012,
            2013,
            2014,
            2009,
            2014,
            2005,
            2015,
            2008,
            2012,
            2016,
            2017,
            2013,
            2010,
            2016,
            2017,
            2017,
            2017,
            2017,
            2015,
            2014,
            2013,
            2016,
            2017,
            2016,
            2016,
            2014,
            2016,
            2015,
            2015,
            2013,
            2015,
            2015,
            2013,
            2016,
            2011,
            2016,
            2013,
            2012,
            2009,
            2017,
            2016,
            2017,
            2017,
            2017,
            2015,
            2017,
            2016,
            2017,
            2015,
            2014,
            2013,
            2016,
            2015,
            2013,
            2016,
            2015,
            2016,
            2014,
            2012,
            2014,
            2015,
            2010,
            2016,
            2011,
            2016,
            2012,
            2013,
            2014,
            2017,
            2017,
            2015,
            2017,
            2017,
            2011,
            2014,
            2012,
            2010,
            2016,
            2016,
            2016,
            2014,
            2013,
            2015,
            2012,
            2015,
            2014,
            2017,
            2015,
            2011,
            2011,
            2016,
            2014,
            2010,
            2012,
            2016,
            2013,
            2013,
            2008,
            2008,
            2010,
            2013,
            2013,
            2005,
            2008,
            2012,
            2007,
            2013,
            2008,
            2015,
            2008,
            2010,
            2011,
            2007,
            2006,
            2010,
            2015,
            2011,
            2015,
            2016,
            2017,
            2015,
            2017,
            2015,
            2012,
            2015,
            2016,
            2011,
            2017,
            2012,
            2016,
            2016,
            2014,
            2012,
            2017,
            2013,
            2014,
            2015,
            2013,
            2011,
            2015,
            2011,
            2012,
            2012,
            2013,
            2017,
            2015,
            2013,
            2015,
            2017,
            2016,
            2015,
            2013,
            2012,
            2012,
            2015,
            2014,
            2016,
            2013,
            2012,
            2012,
            2015,
            2013,
            2016,
            2016,
            2013,
            2015,
            2014,
            2013,
            2012,
            2016,
            2015,
            2015,
            2014,
            2016,
            2016,
            2015,
            2016,
            2015,
            2017,
            2014,
            2016,
            2017,
            2015,
            2011,
            2009,
            2015,
            2010,
            2014,
            2016,
            2015,
            2015,
            2016,
            2014,
            2015,
            2006,
            2014,
            2016,
            2013,
            2016,
            2016,
            2015,
            2015,
            2016,
            2014,
            2015,
            2016,
            2010,
            2014,
            2015,
            2016,
            2015,
            2009,
            2017,
            2016
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "Selling_Price",
           "values": [
            3.35,
            4.75,
            7.25,
            2.85,
            4.6,
            9.25,
            6.75,
            6.5,
            8.75,
            7.45,
            2.85,
            6.85,
            7.5,
            6.1,
            2.25,
            7.75,
            7.25,
            7.75,
            3.25,
            2.65,
            2.85,
            4.9,
            4.4,
            2.5,
            2.9,
            3.0,
            4.15,
            6.0,
            1.95,
            7.45,
            3.1,
            2.35,
            4.95,
            6.0,
            5.5,
            2.95,
            4.65,
            0.35,
            3.0,
            2.25,
            5.85,
            2.55,
            1.95,
            5.5,
            1.25,
            7.5,
            2.65,
            1.05,
            5.8,
            7.75,
            14.9,
            23.0,
            18.0,
            16.0,
            2.75,
            3.6,
            4.5,
            4.75,
            4.1,
            19.99,
            6.95,
            4.5,
            18.75,
            23.5,
            33.0,
            4.75,
            19.75,
            9.25,
            4.35,
            14.25,
            3.95,
            4.5,
            7.45,
            2.65,
            4.9,
            3.95,
            5.5,
            1.5,
            5.25,
            14.5,
            14.73,
            4.75,
            23.0,
            12.5,
            3.49,
            2.5,
            35.0,
            5.9,
            3.45,
            4.75,
            3.8,
            11.25,
            3.51,
            23.0,
            4.0,
            5.85,
            20.75,
            17.0,
            7.05,
            9.65,
            1.75,
            1.7,
            1.65,
            1.45,
            1.35,
            1.35,
            1.35,
            1.25,
            1.2,
            1.2,
            1.2,
            1.15,
            1.15,
            1.15,
            1.15,
            1.11,
            1.1,
            1.1,
            1.1,
            1.05,
            1.05,
            1.05,
            1.05,
            1.0,
            0.95,
            0.9,
            0.9,
            0.75,
            0.8,
            0.78,
            0.75,
            0.75,
            0.75,
            0.72,
            0.65,
            0.65,
            0.65,
            0.65,
            0.6,
            0.6,
            0.6,
            0.6,
            0.6,
            0.6,
            0.6,
            0.6,
            0.55,
            0.55,
            0.52,
            0.51,
            0.5,
            0.5,
            0.5,
            0.5,
            0.5,
            0.48,
            0.48,
            0.48,
            0.48,
            0.45,
            0.45,
            0.45,
            0.45,
            0.45,
            0.45,
            0.45,
            0.45,
            0.42,
            0.42,
            0.4,
            0.4,
            0.4,
            0.4,
            0.4,
            0.38,
            0.38,
            0.35,
            0.35,
            0.35,
            0.31,
            0.3,
            0.3,
            0.3,
            0.27,
            0.25,
            0.25,
            0.25,
            0.25,
            0.25,
            0.2,
            0.2,
            0.2,
            0.2,
            0.2,
            0.2,
            0.18,
            0.17,
            0.16,
            0.15,
            0.12,
            0.1,
            3.25,
            4.4,
            2.95,
            2.75,
            5.25,
            5.75,
            5.15,
            7.9,
            4.85,
            3.1,
            11.75,
            11.25,
            2.9,
            5.25,
            4.5,
            2.9,
            3.15,
            6.45,
            4.5,
            3.5,
            4.5,
            6.0,
            8.25,
            5.11,
            2.7,
            5.25,
            2.55,
            4.95,
            3.1,
            6.15,
            9.25,
            11.45,
            3.9,
            5.5,
            9.1,
            3.1,
            11.25,
            4.8,
            2.0,
            5.35,
            4.75,
            4.4,
            6.25,
            5.95,
            5.2,
            3.75,
            5.95,
            4.0,
            5.25,
            12.9,
            5.0,
            5.4,
            7.2,
            5.25,
            3.0,
            10.25,
            8.5,
            8.4,
            3.9,
            9.15,
            5.5,
            4.0,
            6.6,
            4.0,
            6.5,
            3.65,
            8.35,
            4.8,
            6.7,
            4.1,
            3.0,
            7.5,
            2.25,
            5.3,
            10.9,
            8.65,
            9.7,
            6.0,
            6.25,
            5.25,
            2.1,
            8.25,
            8.99,
            3.5,
            7.4,
            5.65,
            5.75,
            8.4,
            10.11,
            4.5,
            5.4,
            6.4,
            3.25,
            3.75,
            8.55,
            9.5,
            4.0,
            3.35,
            11.5,
            5.3
           ]
          }
         ],
         "hovertemplate": "%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}<br>Selling_Price=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           3.35,
           4.75,
           7.25,
           2.85,
           4.6,
           9.25,
           6.75,
           6.5,
           8.75,
           7.45,
           2.85,
           6.85,
           7.5,
           6.1,
           2.25,
           7.75,
           7.25,
           7.75,
           3.25,
           2.65,
           2.85,
           4.9,
           4.4,
           2.5,
           2.9,
           3.0,
           4.15,
           6.0,
           1.95,
           7.45,
           3.1,
           2.35,
           4.95,
           6.0,
           5.5,
           2.95,
           4.65,
           0.35,
           3.0,
           2.25,
           5.85,
           2.55,
           1.95,
           5.5,
           1.25,
           7.5,
           2.65,
           1.05,
           5.8,
           7.75,
           14.9,
           23.0,
           18.0,
           16.0,
           2.75,
           3.6,
           4.5,
           4.75,
           4.1,
           19.99,
           6.95,
           4.5,
           18.75,
           23.5,
           33.0,
           4.75,
           19.75,
           9.25,
           4.35,
           14.25,
           3.95,
           4.5,
           7.45,
           2.65,
           4.9,
           3.95,
           5.5,
           1.5,
           5.25,
           14.5,
           14.73,
           4.75,
           23.0,
           12.5,
           3.49,
           2.5,
           35.0,
           5.9,
           3.45,
           4.75,
           3.8,
           11.25,
           3.51,
           23.0,
           4.0,
           5.85,
           20.75,
           17.0,
           7.05,
           9.65,
           1.75,
           1.7,
           1.65,
           1.45,
           1.35,
           1.35,
           1.35,
           1.25,
           1.2,
           1.2,
           1.2,
           1.15,
           1.15,
           1.15,
           1.15,
           1.11,
           1.1,
           1.1,
           1.1,
           1.05,
           1.05,
           1.05,
           1.05,
           1.0,
           0.95,
           0.9,
           0.9,
           0.75,
           0.8,
           0.78,
           0.75,
           0.75,
           0.75,
           0.72,
           0.65,
           0.65,
           0.65,
           0.65,
           0.6,
           0.6,
           0.6,
           0.6,
           0.6,
           0.6,
           0.6,
           0.6,
           0.55,
           0.55,
           0.52,
           0.51,
           0.5,
           0.5,
           0.5,
           0.5,
           0.5,
           0.48,
           0.48,
           0.48,
           0.48,
           0.45,
           0.45,
           0.45,
           0.45,
           0.45,
           0.45,
           0.45,
           0.45,
           0.42,
           0.42,
           0.4,
           0.4,
           0.4,
           0.4,
           0.4,
           0.38,
           0.38,
           0.35,
           0.35,
           0.35,
           0.31,
           0.3,
           0.3,
           0.3,
           0.27,
           0.25,
           0.25,
           0.25,
           0.25,
           0.25,
           0.2,
           0.2,
           0.2,
           0.2,
           0.2,
           0.2,
           0.18,
           0.17,
           0.16,
           0.15,
           0.12,
           0.1,
           3.25,
           4.4,
           2.95,
           2.75,
           5.25,
           5.75,
           5.15,
           7.9,
           4.85,
           3.1,
           11.75,
           11.25,
           2.9,
           5.25,
           4.5,
           2.9,
           3.15,
           6.45,
           4.5,
           3.5,
           4.5,
           6.0,
           8.25,
           5.11,
           2.7,
           5.25,
           2.55,
           4.95,
           3.1,
           6.15,
           9.25,
           11.45,
           3.9,
           5.5,
           9.1,
           3.1,
           11.25,
           4.8,
           2.0,
           5.35,
           4.75,
           4.4,
           6.25,
           5.95,
           5.2,
           3.75,
           5.95,
           4.0,
           5.25,
           12.9,
           5.0,
           5.4,
           7.2,
           5.25,
           3.0,
           10.25,
           8.5,
           8.4,
           3.9,
           9.15,
           5.5,
           4.0,
           6.6,
           4.0,
           6.5,
           3.65,
           8.35,
           4.8,
           6.7,
           4.1,
           3.0,
           7.5,
           2.25,
           5.3,
           10.9,
           8.65,
           9.7,
           6.0,
           6.25,
           5.25,
           2.1,
           8.25,
           8.99,
           3.5,
           7.4,
           5.65,
           5.75,
           8.4,
           10.11,
           4.5,
           5.4,
           6.4,
           3.25,
           3.75,
           8.55,
           9.5,
           4.0,
           3.35,
           11.5,
           5.3
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle"
         },
         "name": "",
         "showlegend": false,
         "type": "splom"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "bgcolor": "rgb(17,17,17)",
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "rgb(17,17,17)",
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "subunitcolor": "#506784",
           "showland": true,
           "showlakes": true,
           "lakecolor": "rgb(17,17,17)"
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "borderwidth": 1,
           "bordercolor": "rgb(17,17,17)",
           "tickwidth": 0
          },
          "mapbox": {
           "style": "dark"
          }
         }
        },
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Selling_Price"
          }
         },
         "colorscale": [
          [
           0.0,
           "rgb(252, 222, 156)"
          ],
          [
           0.16666666666666666,
           "rgb(250, 164, 118)"
          ],
          [
           0.3333333333333333,
           "rgb(240, 116, 110)"
          ],
          [
           0.5,
           "rgb(227, 79, 111)"
          ],
          [
           0.6666666666666666,
           "rgb(220, 57, 119)"
          ],
          [
           0.8333333333333334,
           "rgb(185, 37, 122)"
          ],
          [
           1.0,
           "rgb(124, 29, 111)"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "title": {
         "text": "Regression  for all variables vs Selling_Price in plotly dark theme"
        },
        "dragmode": "select",
        "width": 1000,
        "height": 600
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"8875d51a-5bcc-4bc6-9d71-a7d2eabbe300\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8875d51a-5bcc-4bc6-9d71-a7d2eabbe300\")) {                    Plotly.newPlot(                        \"8875d51a-5bcc-4bc6-9d71-a7d2eabbe300\",                        [{\"dimensions\":[{\"axis\":{\"matches\":true},\"label\":\"Present_Price\",\"values\":[5.59,9.54,9.85,4.15,6.87,9.83,8.12,8.61,8.89,8.92,3.6,10.38,9.94,7.71,7.21,10.79,10.79,10.79,5.09,7.98,3.95,5.71,8.01,3.46,4.41,4.99,5.87,6.49,3.95,10.38,5.98,4.89,7.49,9.95,8.06,7.74,7.2,2.28,3.76,7.98,7.87,3.98,7.15,8.06,2.69,12.04,4.89,4.15,7.71,9.29,30.61,30.61,19.77,30.61,10.21,15.04,7.27,18.54,6.8,35.96,18.61,7.7,35.96,35.96,36.23,6.95,23.15,20.45,13.74,20.91,6.76,12.48,18.61,5.71,8.93,6.8,14.68,12.35,22.83,30.61,14.89,7.85,25.39,13.46,13.46,23.73,92.6,13.74,6.05,6.76,18.61,16.09,13.7,30.61,22.78,18.61,25.39,18.64,18.61,20.45,1.9,1.82,1.78,1.6,1.47,2.37,3.45,1.5,1.5,1.47,1.78,1.5,2.4,1.4,1.47,1.47,1.47,1.9,1.47,1.9,1.26,1.5,1.17,1.47,1.75,1.75,0.95,0.8,0.87,0.84,0.87,0.82,0.95,0.95,0.81,0.74,1.2,0.787,0.87,0.95,1.2,0.8,0.84,0.84,0.99,0.81,0.787,0.84,0.94,0.94,0.826,0.55,0.99,0.99,0.88,0.51,0.52,0.84,0.54,0.51,0.95,0.826,0.99,0.95,0.54,0.54,0.55,0.81,0.73,0.54,0.83,0.55,0.64,0.51,0.72,0.787,1.05,0.57,0.52,1.05,0.51,0.48,0.58,0.47,0.75,0.58,0.52,0.51,0.57,0.57,0.75,0.57,0.75,0.65,0.787,0.32,0.52,0.51,0.57,0.58,0.75,6.79,5.7,4.6,4.43,5.7,7.13,5.7,8.1,5.7,4.6,14.79,13.6,6.79,5.7,9.4,4.43,4.43,9.4,9.4,4.43,6.79,7.6,9.4,9.4,4.6,5.7,4.43,9.4,6.79,9.4,9.4,14.79,5.7,5.7,9.4,4.43,13.6,9.4,4.43,9.4,7.13,7.13,7.6,9.4,9.4,6.79,9.4,4.6,7.6,13.6,9.9,6.82,9.9,9.9,5.35,13.6,13.6,13.6,7.0,13.6,5.97,5.8,7.7,7.0,8.7,7.0,9.4,5.8,10.0,10.0,10.0,10.0,7.5,6.8,13.6,13.6,13.6,8.4,13.6,5.9,7.6,14.0,11.8,5.9,8.5,7.9,7.5,13.6,13.6,6.4,6.1,8.4,9.9,6.8,13.09,11.6,5.9,11.0,12.5,5.9]},{\"axis\":{\"matches\":true},\"label\":\"Kms_Driven\",\"values\":[27000,43000,6900,5200,42450,2071,18796,33429,20273,42367,2135,51000,15000,26000,77427,43000,41678,43000,35500,41442,25000,2400,50000,45280,56879,20000,55138,16200,44542,45000,51439,54200,39000,45000,45000,49998,48767,127000,10079,62000,24524,46706,58000,45780,50000,15000,64532,65000,25870,37000,104707,40000,15000,135000,90000,70000,40534,50000,39485,41000,40001,40588,78000,47000,6000,45000,11000,59000,88000,12000,71000,45000,56001,43000,83000,36000,72000,135154,80000,89000,23000,40000,15000,38000,197176,142000,78000,56000,47000,40000,62000,58242,75000,40000,89000,72000,29000,8700,45000,50024,3000,1400,4000,1200,4100,21700,16500,15000,18000,11000,6000,8700,7000,35000,17000,17500,33000,14000,26000,5400,5700,6900,6000,46500,11500,40000,1300,7000,3000,5000,11000,18000,3500,500,11800,5000,23500,16000,15000,16600,32000,20000,29000,25000,25000,19000,15000,58000,45000,24000,6000,31000,13000,45000,8000,4300,15000,23000,8600,4000,24000,23000,14500,27000,14000,500,1000,42000,12000,14000,5500,6700,13700,1300,38600,75000,30000,24000,19000,213000,60000,50000,30000,21000,26000,1900,22000,32000,18000,55000,60000,25000,49000,24000,50000,35000,500000,33000,35000,53000,92233,58000,28200,53460,28282,3493,12479,34797,3435,21125,35775,43535,22671,31604,20114,36100,12500,15000,45078,36000,38488,32000,77632,61381,36198,22517,24678,57000,60000,52132,45000,15001,12900,53000,4492,15141,11849,68000,60241,23709,32322,35866,34000,7000,49000,71000,35000,36000,30000,17000,35934,56701,31427,48000,54242,53675,49562,40324,25000,36054,29223,5600,40023,16002,40026,21200,35000,19434,19000,18828,69341,69562,27600,61203,16500,30753,24800,21780,4000,40126,14465,50456,63000,9010,9800,15059,28569,44000,34000,10980,19000,31427,12000,38000,33019,60076,33988,60000,87934,9000,5464]},{\"axis\":{\"matches\":true},\"label\":\"Owner\",\"values\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{\"axis\":{\"matches\":true},\"label\":\"Year\",\"values\":[2014,2013,2017,2011,2014,2018,2015,2015,2016,2015,2017,2015,2015,2015,2009,2016,2015,2016,2015,2010,2016,2017,2011,2014,2013,2011,2013,2017,2010,2015,2012,2011,2014,2014,2014,2011,2015,2003,2016,2003,2016,2014,2008,2014,2012,2014,2013,2006,2015,2017,2012,2015,2017,2013,2005,2009,2015,2010,2014,2014,2013,2015,2014,2015,2017,2014,2017,2010,2011,2016,2014,2011,2013,2011,2014,2015,2013,2004,2010,2012,2016,2015,2017,2015,2005,2006,2010,2012,2013,2014,2009,2014,2005,2015,2008,2012,2016,2017,2013,2010,2016,2017,2017,2017,2017,2015,2014,2013,2016,2017,2016,2016,2014,2016,2015,2015,2013,2015,2015,2013,2016,2011,2016,2013,2012,2009,2017,2016,2017,2017,2017,2015,2017,2016,2017,2015,2014,2013,2016,2015,2013,2016,2015,2016,2014,2012,2014,2015,2010,2016,2011,2016,2012,2013,2014,2017,2017,2015,2017,2017,2011,2014,2012,2010,2016,2016,2016,2014,2013,2015,2012,2015,2014,2017,2015,2011,2011,2016,2014,2010,2012,2016,2013,2013,2008,2008,2010,2013,2013,2005,2008,2012,2007,2013,2008,2015,2008,2010,2011,2007,2006,2010,2015,2011,2015,2016,2017,2015,2017,2015,2012,2015,2016,2011,2017,2012,2016,2016,2014,2012,2017,2013,2014,2015,2013,2011,2015,2011,2012,2012,2013,2017,2015,2013,2015,2017,2016,2015,2013,2012,2012,2015,2014,2016,2013,2012,2012,2015,2013,2016,2016,2013,2015,2014,2013,2012,2016,2015,2015,2014,2016,2016,2015,2016,2015,2017,2014,2016,2017,2015,2011,2009,2015,2010,2014,2016,2015,2015,2016,2014,2015,2006,2014,2016,2013,2016,2016,2015,2015,2016,2014,2015,2016,2010,2014,2015,2016,2015,2009,2017,2016]},{\"axis\":{\"matches\":true},\"label\":\"Selling_Price\",\"values\":[3.35,4.75,7.25,2.85,4.6,9.25,6.75,6.5,8.75,7.45,2.85,6.85,7.5,6.1,2.25,7.75,7.25,7.75,3.25,2.65,2.85,4.9,4.4,2.5,2.9,3.0,4.15,6.0,1.95,7.45,3.1,2.35,4.95,6.0,5.5,2.95,4.65,0.35,3.0,2.25,5.85,2.55,1.95,5.5,1.25,7.5,2.65,1.05,5.8,7.75,14.9,23.0,18.0,16.0,2.75,3.6,4.5,4.75,4.1,19.99,6.95,4.5,18.75,23.5,33.0,4.75,19.75,9.25,4.35,14.25,3.95,4.5,7.45,2.65,4.9,3.95,5.5,1.5,5.25,14.5,14.73,4.75,23.0,12.5,3.49,2.5,35.0,5.9,3.45,4.75,3.8,11.25,3.51,23.0,4.0,5.85,20.75,17.0,7.05,9.65,1.75,1.7,1.65,1.45,1.35,1.35,1.35,1.25,1.2,1.2,1.2,1.15,1.15,1.15,1.15,1.11,1.1,1.1,1.1,1.05,1.05,1.05,1.05,1.0,0.95,0.9,0.9,0.75,0.8,0.78,0.75,0.75,0.75,0.72,0.65,0.65,0.65,0.65,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.55,0.55,0.52,0.51,0.5,0.5,0.5,0.5,0.5,0.48,0.48,0.48,0.48,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.42,0.42,0.4,0.4,0.4,0.4,0.4,0.38,0.38,0.35,0.35,0.35,0.31,0.3,0.3,0.3,0.27,0.25,0.25,0.25,0.25,0.25,0.2,0.2,0.2,0.2,0.2,0.2,0.18,0.17,0.16,0.15,0.12,0.1,3.25,4.4,2.95,2.75,5.25,5.75,5.15,7.9,4.85,3.1,11.75,11.25,2.9,5.25,4.5,2.9,3.15,6.45,4.5,3.5,4.5,6.0,8.25,5.11,2.7,5.25,2.55,4.95,3.1,6.15,9.25,11.45,3.9,5.5,9.1,3.1,11.25,4.8,2.0,5.35,4.75,4.4,6.25,5.95,5.2,3.75,5.95,4.0,5.25,12.9,5.0,5.4,7.2,5.25,3.0,10.25,8.5,8.4,3.9,9.15,5.5,4.0,6.6,4.0,6.5,3.65,8.35,4.8,6.7,4.1,3.0,7.5,2.25,5.3,10.9,8.65,9.7,6.0,6.25,5.25,2.1,8.25,8.99,3.5,7.4,5.65,5.75,8.4,10.11,4.5,5.4,6.4,3.25,3.75,8.55,9.5,4.0,3.35,11.5,5.3]}],\"hovertemplate\":\"%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}<br>Selling_Price=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[3.35,4.75,7.25,2.85,4.6,9.25,6.75,6.5,8.75,7.45,2.85,6.85,7.5,6.1,2.25,7.75,7.25,7.75,3.25,2.65,2.85,4.9,4.4,2.5,2.9,3.0,4.15,6.0,1.95,7.45,3.1,2.35,4.95,6.0,5.5,2.95,4.65,0.35,3.0,2.25,5.85,2.55,1.95,5.5,1.25,7.5,2.65,1.05,5.8,7.75,14.9,23.0,18.0,16.0,2.75,3.6,4.5,4.75,4.1,19.99,6.95,4.5,18.75,23.5,33.0,4.75,19.75,9.25,4.35,14.25,3.95,4.5,7.45,2.65,4.9,3.95,5.5,1.5,5.25,14.5,14.73,4.75,23.0,12.5,3.49,2.5,35.0,5.9,3.45,4.75,3.8,11.25,3.51,23.0,4.0,5.85,20.75,17.0,7.05,9.65,1.75,1.7,1.65,1.45,1.35,1.35,1.35,1.25,1.2,1.2,1.2,1.15,1.15,1.15,1.15,1.11,1.1,1.1,1.1,1.05,1.05,1.05,1.05,1.0,0.95,0.9,0.9,0.75,0.8,0.78,0.75,0.75,0.75,0.72,0.65,0.65,0.65,0.65,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.55,0.55,0.52,0.51,0.5,0.5,0.5,0.5,0.5,0.48,0.48,0.48,0.48,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.42,0.42,0.4,0.4,0.4,0.4,0.4,0.38,0.38,0.35,0.35,0.35,0.31,0.3,0.3,0.3,0.27,0.25,0.25,0.25,0.25,0.25,0.2,0.2,0.2,0.2,0.2,0.2,0.18,0.17,0.16,0.15,0.12,0.1,3.25,4.4,2.95,2.75,5.25,5.75,5.15,7.9,4.85,3.1,11.75,11.25,2.9,5.25,4.5,2.9,3.15,6.45,4.5,3.5,4.5,6.0,8.25,5.11,2.7,5.25,2.55,4.95,3.1,6.15,9.25,11.45,3.9,5.5,9.1,3.1,11.25,4.8,2.0,5.35,4.75,4.4,6.25,5.95,5.2,3.75,5.95,4.0,5.25,12.9,5.0,5.4,7.2,5.25,3.0,10.25,8.5,8.4,3.9,9.15,5.5,4.0,6.6,4.0,6.5,3.65,8.35,4.8,6.7,4.1,3.0,7.5,2.25,5.3,10.9,8.65,9.7,6.0,6.25,5.25,2.1,8.25,8.99,3.5,7.4,5.65,5.75,8.4,10.11,4.5,5.4,6.4,3.25,3.75,8.55,9.5,4.0,3.35,11.5,5.3],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"name\":\"\",\"showlegend\":false,\"type\":\"splom\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Selling_Price\"}},\"colorscale\":[[0.0,\"rgb(252, 222, 156)\"],[0.16666666666666666,\"rgb(250, 164, 118)\"],[0.3333333333333333,\"rgb(240, 116, 110)\"],[0.5,\"rgb(227, 79, 111)\"],[0.6666666666666666,\"rgb(220, 57, 119)\"],[0.8333333333333334,\"rgb(185, 37, 122)\"],[1.0,\"rgb(124, 29, 111)\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Regression  for all variables vs Selling_Price in plotly dark theme\"},\"dragmode\":\"select\",\"width\":1000,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('8875d51a-5bcc-4bc6-9d71-a7d2eabbe300');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Regression for all variables vs Selling_Price in plotly dark theme\n",
    "\n",
    "fig = px.scatter_matrix(train0, dimensions=[\"Present_Price\", \"Kms_Driven\", \"Owner\", \"Year\", \"Selling_Price\"], color=\"Selling_Price\", title=\"Regression  for all variables vs Selling_Price in plotly dark theme\")\n",
    "fig.update_traces(diagonal_visible=False, marker=dict(size=2, line=dict(width=1, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "fig.update_layout(width=1000, height=600)\n",
    "# invert the colorscale for the y-axis\n",
    "fig.update_layout(coloraxis_colorscale='sunsetdark')\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:20:57.576717Z",
     "start_time": "2023-05-24T13:20:57.552747Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hint:** For visibility purposes the color is prechoosen. To adjust to audience needs, use one of the following color scales\n",
    "for continuous data.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['aggrnyl',\n 'agsunset',\n 'blackbody',\n 'bluered',\n 'blues',\n 'blugrn',\n 'bluyl',\n 'brwnyl',\n 'bugn',\n 'bupu',\n 'burg',\n 'burgyl',\n 'cividis',\n 'darkmint',\n 'electric',\n 'emrld',\n 'gnbu',\n 'greens',\n 'greys',\n 'hot',\n 'inferno',\n 'jet',\n 'magenta',\n 'magma',\n 'mint',\n 'orrd',\n 'oranges',\n 'oryel',\n 'peach',\n 'pinkyl',\n 'plasma',\n 'plotly3',\n 'pubu',\n 'pubugn',\n 'purd',\n 'purp',\n 'purples',\n 'purpor',\n 'rainbow',\n 'rdbu',\n 'rdpu',\n 'redor',\n 'reds',\n 'sunset',\n 'sunsetdark',\n 'teal',\n 'tealgrn',\n 'turbo',\n 'viridis',\n 'ylgn',\n 'ylgnbu',\n 'ylorbr',\n 'ylorrd',\n 'algae',\n 'amp',\n 'deep',\n 'dense',\n 'gray',\n 'haline',\n 'ice',\n 'matter',\n 'solar',\n 'speed',\n 'tempo',\n 'thermal',\n 'turbid',\n 'armyrose',\n 'brbg',\n 'earth',\n 'fall',\n 'geyser',\n 'prgn',\n 'piyg',\n 'picnic',\n 'portland',\n 'puor',\n 'rdgy',\n 'rdylbu',\n 'rdylgn',\n 'spectral',\n 'tealrose',\n 'temps',\n 'tropic',\n 'balance',\n 'curl',\n 'delta',\n 'oxy',\n 'edge',\n 'hsv',\n 'icefire',\n 'phase',\n 'twilight',\n 'mrybm',\n 'mygbm']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_colorscales = list(px.colors.named_colorscales())\n",
    "named_colorscales"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:20:59.197287Z",
     "start_time": "2023-05-24T13:20:59.188840Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **2. Data Preprocessing**\n",
    "In the second step we will preprocess the data. We will look at the data types, missing values, and the distribution of the data. We will also look at the correlation between the variables and the target variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Determination categorical features\n",
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "categorical_columns = []\n",
    "features = train0.columns.values.tolist()\n",
    "for col in features:\n",
    "    if train0[col].dtype in numerics: continue\n",
    "    categorical_columns.append(col)\n",
    "# Encoding categorical features\n",
    "for col in categorical_columns:\n",
    "    if col in train0.columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train0[col].astype(str).values))\n",
    "        train0[col] = le.transform(list(train0[col].astype(str).values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:01.326936Z",
     "start_time": "2023-05-24T13:21:01.307486Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train0['Year'] = (train0['Year']-1900).astype(int)\n",
    "train0['Selling_Price'] = train0['Selling_Price'].astype(int)\n",
    "train0['Present_Price'] = train0['Present_Price'].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:02.212013Z",
     "start_time": "2023-05-24T13:21:02.202328Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 301 entries, 0 to 300\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype\n",
      "---  ------         --------------  -----\n",
      " 0   Car_Name       301 non-null    int64\n",
      " 1   Year           301 non-null    int64\n",
      " 2   Selling_Price  301 non-null    int64\n",
      " 3   Present_Price  301 non-null    int64\n",
      " 4   Kms_Driven     301 non-null    int64\n",
      " 5   Fuel_Type      301 non-null    int64\n",
      " 6   Seller_Type    301 non-null    int64\n",
      " 7   Transmission   301 non-null    int64\n",
      " 8   Owner          301 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 21.3 KB\n"
     ]
    }
   ],
   "source": [
    "train0.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:03.004619Z",
     "start_time": "2023-05-24T13:21:02.980706Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Selling_Price\n0     78\n4     34\n5     30\n1     29\n3     28\n2     24\n6     17\n7     15\n8     10\n9      8\n11     6\n23     4\n14     4\n10     3\n18     2\n19     2\n12     2\n16     1\n33     1\n35     1\n20     1\n17     1\nName: count, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train0['Selling_Price'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:03.935939Z",
     "start_time": "2023-05-24T13:21:03.926591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "               Car_Name      Year  Selling_Price  Present_Price  Kms_Driven   \nCar_Name       1.000000  0.017265       0.492795       0.479768    0.064453  \\\nYear           0.017265  1.000000       0.229302      -0.049269   -0.524342   \nSelling_Price  0.492795  0.229302       1.000000       0.877518    0.032597   \nPresent_Price  0.479768 -0.049269       0.877518       1.000000    0.206896   \nKms_Driven     0.064453 -0.524342       0.032597       0.206896    1.000000   \nFuel_Type     -0.371446 -0.053643      -0.503878      -0.439934   -0.166801   \nSeller_Type   -0.829718 -0.039896      -0.542332      -0.515092   -0.101419   \nTransmission  -0.059855  0.000394      -0.367935      -0.349275   -0.162510   \nOwner         -0.081192 -0.182104      -0.083877       0.007089    0.089216   \n\n               Fuel_Type  Seller_Type  Transmission     Owner  \nCar_Name       -0.371446    -0.829718     -0.059855 -0.081192  \nYear           -0.053643    -0.039896      0.000394 -0.182104  \nSelling_Price  -0.503878    -0.542332     -0.367935 -0.083877  \nPresent_Price  -0.439934    -0.515092     -0.349275  0.007089  \nKms_Driven     -0.166801    -0.101419     -0.162510  0.089216  \nFuel_Type       1.000000     0.352415      0.080466  0.055705  \nSeller_Type     0.352415     1.000000      0.063240  0.124269  \nTransmission    0.080466     0.063240      1.000000 -0.050316  \nOwner           0.055705     0.124269     -0.050316  1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Car_Name</th>\n      <th>Year</th>\n      <th>Selling_Price</th>\n      <th>Present_Price</th>\n      <th>Kms_Driven</th>\n      <th>Fuel_Type</th>\n      <th>Seller_Type</th>\n      <th>Transmission</th>\n      <th>Owner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Car_Name</th>\n      <td>1.000000</td>\n      <td>0.017265</td>\n      <td>0.492795</td>\n      <td>0.479768</td>\n      <td>0.064453</td>\n      <td>-0.371446</td>\n      <td>-0.829718</td>\n      <td>-0.059855</td>\n      <td>-0.081192</td>\n    </tr>\n    <tr>\n      <th>Year</th>\n      <td>0.017265</td>\n      <td>1.000000</td>\n      <td>0.229302</td>\n      <td>-0.049269</td>\n      <td>-0.524342</td>\n      <td>-0.053643</td>\n      <td>-0.039896</td>\n      <td>0.000394</td>\n      <td>-0.182104</td>\n    </tr>\n    <tr>\n      <th>Selling_Price</th>\n      <td>0.492795</td>\n      <td>0.229302</td>\n      <td>1.000000</td>\n      <td>0.877518</td>\n      <td>0.032597</td>\n      <td>-0.503878</td>\n      <td>-0.542332</td>\n      <td>-0.367935</td>\n      <td>-0.083877</td>\n    </tr>\n    <tr>\n      <th>Present_Price</th>\n      <td>0.479768</td>\n      <td>-0.049269</td>\n      <td>0.877518</td>\n      <td>1.000000</td>\n      <td>0.206896</td>\n      <td>-0.439934</td>\n      <td>-0.515092</td>\n      <td>-0.349275</td>\n      <td>0.007089</td>\n    </tr>\n    <tr>\n      <th>Kms_Driven</th>\n      <td>0.064453</td>\n      <td>-0.524342</td>\n      <td>0.032597</td>\n      <td>0.206896</td>\n      <td>1.000000</td>\n      <td>-0.166801</td>\n      <td>-0.101419</td>\n      <td>-0.162510</td>\n      <td>0.089216</td>\n    </tr>\n    <tr>\n      <th>Fuel_Type</th>\n      <td>-0.371446</td>\n      <td>-0.053643</td>\n      <td>-0.503878</td>\n      <td>-0.439934</td>\n      <td>-0.166801</td>\n      <td>1.000000</td>\n      <td>0.352415</td>\n      <td>0.080466</td>\n      <td>0.055705</td>\n    </tr>\n    <tr>\n      <th>Seller_Type</th>\n      <td>-0.829718</td>\n      <td>-0.039896</td>\n      <td>-0.542332</td>\n      <td>-0.515092</td>\n      <td>-0.101419</td>\n      <td>0.352415</td>\n      <td>1.000000</td>\n      <td>0.063240</td>\n      <td>0.124269</td>\n    </tr>\n    <tr>\n      <th>Transmission</th>\n      <td>-0.059855</td>\n      <td>0.000394</td>\n      <td>-0.367935</td>\n      <td>-0.349275</td>\n      <td>-0.162510</td>\n      <td>0.080466</td>\n      <td>0.063240</td>\n      <td>1.000000</td>\n      <td>-0.050316</td>\n    </tr>\n    <tr>\n      <th>Owner</th>\n      <td>-0.081192</td>\n      <td>-0.182104</td>\n      <td>-0.083877</td>\n      <td>0.007089</td>\n      <td>0.089216</td>\n      <td>0.055705</td>\n      <td>0.124269</td>\n      <td>-0.050316</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train0.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:04.964664Z",
     "start_time": "2023-05-24T13:21:04.946275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorscale": [
          [
           0.0,
           "rgb(0, 155, 158)"
          ],
          [
           0.16666666666666666,
           "rgb(66, 183, 185)"
          ],
          [
           0.3333333333333333,
           "rgb(167, 211, 212)"
          ],
          [
           0.5,
           "rgb(241, 241, 241)"
          ],
          [
           0.6666666666666666,
           "rgb(228, 193, 217)"
          ],
          [
           0.8333333333333334,
           "rgb(214, 145, 193)"
          ],
          [
           1.0,
           "rgb(199, 93, 171)"
          ]
         ],
         "reversescale": false,
         "showscale": false,
         "x": [
          "Car_Name",
          "Year",
          "Selling_Price",
          "Present_Price",
          "Kms_Driven",
          "Fuel_Type",
          "Seller_Type",
          "Transmission",
          "Owner"
         ],
         "y": [
          "Car_Name",
          "Year",
          "Selling_Price",
          "Present_Price",
          "Kms_Driven",
          "Fuel_Type",
          "Seller_Type",
          "Transmission",
          "Owner"
         ],
         "z": [
          [
           1.0,
           0.017264556300864233,
           0.49279510744608307,
           0.47976845462775325,
           0.06445292436299085,
           -0.3714455823762248,
           -0.8297177868014962,
           -0.05985545294237017,
           -0.081191957347104
          ],
          [
           0.017264556300864233,
           1.0,
           0.2293016790062059,
           -0.04926919956191409,
           -0.5243420406957308,
           -0.053642815639504335,
           -0.0398962975158734,
           3.9422357639061804E-4,
           -0.18210355920226182
          ],
          [
           0.49279510744608307,
           0.2293016790062059,
           1.0,
           0.8775184749681499,
           0.03259659333042898,
           -0.5038778370896142,
           -0.5423318661691973,
           -0.36793452672531024,
           -0.08387745431547668
          ],
          [
           0.47976845462775325,
           -0.04926919956191409,
           0.8775184749681499,
           1.0,
           0.20689604679426146,
           -0.4399335061373562,
           -0.5150923288475668,
           -0.3492748053692272,
           0.007089428962942723
          ],
          [
           0.06445292436299085,
           -0.5243420406957308,
           0.03259659333042898,
           0.20689604679426146,
           1.0,
           -0.16680064211583787,
           -0.1014191620112754,
           -0.16251006101732512,
           0.08921620186144577
          ],
          [
           -0.3714455823762248,
           -0.053642815639504335,
           -0.5038778370896142,
           -0.4399335061373562,
           -0.16680064211583787,
           1.0,
           0.35241543015455323,
           0.08046640939583319,
           0.055705382613134645
          ],
          [
           -0.8297177868014962,
           -0.0398962975158734,
           -0.5423318661691973,
           -0.5150923288475668,
           -0.1014191620112754,
           0.35241543015455323,
           1.0,
           0.06324049001061859,
           0.1242685770981546
          ],
          [
           -0.05985545294237017,
           3.9422357639061804E-4,
           -0.36793452672531024,
           -0.3492748053692272,
           -0.16251006101732512,
           0.08046640939583319,
           0.06324049001061859,
           1.0,
           -0.050315527841782205
          ],
          [
           -0.081191957347104,
           -0.18210355920226182,
           -0.08387745431547668,
           0.007089428962942723,
           0.08921620186144577,
           0.055705382613134645,
           0.1242685770981546,
           -0.050315527841782205,
           1.0
          ]
         ],
         "type": "heatmap"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "Car_Name",
          "xref": "x",
          "y": "Car_Name",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.02",
          "x": "Year",
          "xref": "x",
          "y": "Car_Name",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.49",
          "x": "Selling_Price",
          "xref": "x",
          "y": "Car_Name",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.48",
          "x": "Present_Price",
          "xref": "x",
          "y": "Car_Name",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.06",
          "x": "Kms_Driven",
          "xref": "x",
          "y": "Car_Name",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.37",
          "x": "Fuel_Type",
          "xref": "x",
          "y": "Car_Name",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.83",
          "x": "Seller_Type",
          "xref": "x",
          "y": "Car_Name",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.06",
          "x": "Transmission",
          "xref": "x",
          "y": "Car_Name",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.08",
          "x": "Owner",
          "xref": "x",
          "y": "Car_Name",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.02",
          "x": "Car_Name",
          "xref": "x",
          "y": "Year",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "Year",
          "xref": "x",
          "y": "Year",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.23",
          "x": "Selling_Price",
          "xref": "x",
          "y": "Year",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.05",
          "x": "Present_Price",
          "xref": "x",
          "y": "Year",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.52",
          "x": "Kms_Driven",
          "xref": "x",
          "y": "Year",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.05",
          "x": "Fuel_Type",
          "xref": "x",
          "y": "Year",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.04",
          "x": "Seller_Type",
          "xref": "x",
          "y": "Year",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Transmission",
          "xref": "x",
          "y": "Year",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.18",
          "x": "Owner",
          "xref": "x",
          "y": "Year",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.49",
          "x": "Car_Name",
          "xref": "x",
          "y": "Selling_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.23",
          "x": "Year",
          "xref": "x",
          "y": "Selling_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "Selling_Price",
          "xref": "x",
          "y": "Selling_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.88",
          "x": "Present_Price",
          "xref": "x",
          "y": "Selling_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.03",
          "x": "Kms_Driven",
          "xref": "x",
          "y": "Selling_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.5",
          "x": "Fuel_Type",
          "xref": "x",
          "y": "Selling_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.54",
          "x": "Seller_Type",
          "xref": "x",
          "y": "Selling_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.37",
          "x": "Transmission",
          "xref": "x",
          "y": "Selling_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.08",
          "x": "Owner",
          "xref": "x",
          "y": "Selling_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.48",
          "x": "Car_Name",
          "xref": "x",
          "y": "Present_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.05",
          "x": "Year",
          "xref": "x",
          "y": "Present_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.88",
          "x": "Selling_Price",
          "xref": "x",
          "y": "Present_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "Present_Price",
          "xref": "x",
          "y": "Present_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.21",
          "x": "Kms_Driven",
          "xref": "x",
          "y": "Present_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.44",
          "x": "Fuel_Type",
          "xref": "x",
          "y": "Present_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.52",
          "x": "Seller_Type",
          "xref": "x",
          "y": "Present_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.35",
          "x": "Transmission",
          "xref": "x",
          "y": "Present_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.01",
          "x": "Owner",
          "xref": "x",
          "y": "Present_Price",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.06",
          "x": "Car_Name",
          "xref": "x",
          "y": "Kms_Driven",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.52",
          "x": "Year",
          "xref": "x",
          "y": "Kms_Driven",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.03",
          "x": "Selling_Price",
          "xref": "x",
          "y": "Kms_Driven",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.21",
          "x": "Present_Price",
          "xref": "x",
          "y": "Kms_Driven",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "Kms_Driven",
          "xref": "x",
          "y": "Kms_Driven",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.17",
          "x": "Fuel_Type",
          "xref": "x",
          "y": "Kms_Driven",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1",
          "x": "Seller_Type",
          "xref": "x",
          "y": "Kms_Driven",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.16",
          "x": "Transmission",
          "xref": "x",
          "y": "Kms_Driven",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.09",
          "x": "Owner",
          "xref": "x",
          "y": "Kms_Driven",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.37",
          "x": "Car_Name",
          "xref": "x",
          "y": "Fuel_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.05",
          "x": "Year",
          "xref": "x",
          "y": "Fuel_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.5",
          "x": "Selling_Price",
          "xref": "x",
          "y": "Fuel_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.44",
          "x": "Present_Price",
          "xref": "x",
          "y": "Fuel_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.17",
          "x": "Kms_Driven",
          "xref": "x",
          "y": "Fuel_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "Fuel_Type",
          "xref": "x",
          "y": "Fuel_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.35",
          "x": "Seller_Type",
          "xref": "x",
          "y": "Fuel_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.08",
          "x": "Transmission",
          "xref": "x",
          "y": "Fuel_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.06",
          "x": "Owner",
          "xref": "x",
          "y": "Fuel_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.83",
          "x": "Car_Name",
          "xref": "x",
          "y": "Seller_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.04",
          "x": "Year",
          "xref": "x",
          "y": "Seller_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.54",
          "x": "Selling_Price",
          "xref": "x",
          "y": "Seller_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.52",
          "x": "Present_Price",
          "xref": "x",
          "y": "Seller_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1",
          "x": "Kms_Driven",
          "xref": "x",
          "y": "Seller_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.35",
          "x": "Fuel_Type",
          "xref": "x",
          "y": "Seller_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "Seller_Type",
          "xref": "x",
          "y": "Seller_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.06",
          "x": "Transmission",
          "xref": "x",
          "y": "Seller_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.12",
          "x": "Owner",
          "xref": "x",
          "y": "Seller_Type",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.06",
          "x": "Car_Name",
          "xref": "x",
          "y": "Transmission",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0",
          "x": "Year",
          "xref": "x",
          "y": "Transmission",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.37",
          "x": "Selling_Price",
          "xref": "x",
          "y": "Transmission",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.35",
          "x": "Present_Price",
          "xref": "x",
          "y": "Transmission",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.16",
          "x": "Kms_Driven",
          "xref": "x",
          "y": "Transmission",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.08",
          "x": "Fuel_Type",
          "xref": "x",
          "y": "Transmission",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.06",
          "x": "Seller_Type",
          "xref": "x",
          "y": "Transmission",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "Transmission",
          "xref": "x",
          "y": "Transmission",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.05",
          "x": "Owner",
          "xref": "x",
          "y": "Transmission",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.08",
          "x": "Car_Name",
          "xref": "x",
          "y": "Owner",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.18",
          "x": "Year",
          "xref": "x",
          "y": "Owner",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.08",
          "x": "Selling_Price",
          "xref": "x",
          "y": "Owner",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.01",
          "x": "Present_Price",
          "xref": "x",
          "y": "Owner",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.09",
          "x": "Kms_Driven",
          "xref": "x",
          "y": "Owner",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.06",
          "x": "Fuel_Type",
          "xref": "x",
          "y": "Owner",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.12",
          "x": "Seller_Type",
          "xref": "x",
          "y": "Owner",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.05",
          "x": "Transmission",
          "xref": "x",
          "y": "Owner",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "Owner",
          "xref": "x",
          "y": "Owner",
          "yref": "y"
         }
        ],
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "top",
         "ticks": ""
        },
        "yaxis": {
         "dtick": 1,
         "ticks": "",
         "ticksuffix": "  "
        },
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "bgcolor": "rgb(17,17,17)",
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "rgb(17,17,17)",
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "subunitcolor": "#506784",
           "showland": true,
           "showlakes": true,
           "lakecolor": "rgb(17,17,17)"
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "borderwidth": 1,
           "bordercolor": "rgb(17,17,17)",
           "tickwidth": 0
          },
          "mapbox": {
           "style": "dark"
          }
         }
        },
        "title": {
         "text": "Correlation matrix with rounded numbers in size 10x10"
        },
        "width": 1000,
        "height": 600
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"a025eaee-acc1-4308-9662-49ecf7b860d8\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a025eaee-acc1-4308-9662-49ecf7b860d8\")) {                    Plotly.newPlot(                        \"a025eaee-acc1-4308-9662-49ecf7b860d8\",                        [{\"colorscale\":[[0.0,\"rgb(0, 155, 158)\"],[0.16666666666666666,\"rgb(66, 183, 185)\"],[0.3333333333333333,\"rgb(167, 211, 212)\"],[0.5,\"rgb(241, 241, 241)\"],[0.6666666666666666,\"rgb(228, 193, 217)\"],[0.8333333333333334,\"rgb(214, 145, 193)\"],[1.0,\"rgb(199, 93, 171)\"]],\"reversescale\":false,\"showscale\":false,\"x\":[\"Car_Name\",\"Year\",\"Selling_Price\",\"Present_Price\",\"Kms_Driven\",\"Fuel_Type\",\"Seller_Type\",\"Transmission\",\"Owner\"],\"y\":[\"Car_Name\",\"Year\",\"Selling_Price\",\"Present_Price\",\"Kms_Driven\",\"Fuel_Type\",\"Seller_Type\",\"Transmission\",\"Owner\"],\"z\":[[1.0,0.017264556300864233,0.49279510744608307,0.47976845462775325,0.06445292436299085,-0.3714455823762248,-0.8297177868014962,-0.05985545294237017,-0.081191957347104],[0.017264556300864233,1.0,0.2293016790062059,-0.04926919956191409,-0.5243420406957308,-0.053642815639504335,-0.0398962975158734,0.00039422357639061804,-0.18210355920226182],[0.49279510744608307,0.2293016790062059,1.0,0.8775184749681499,0.03259659333042898,-0.5038778370896142,-0.5423318661691973,-0.36793452672531024,-0.08387745431547668],[0.47976845462775325,-0.04926919956191409,0.8775184749681499,1.0,0.20689604679426146,-0.4399335061373562,-0.5150923288475668,-0.3492748053692272,0.007089428962942723],[0.06445292436299085,-0.5243420406957308,0.03259659333042898,0.20689604679426146,1.0,-0.16680064211583787,-0.1014191620112754,-0.16251006101732512,0.08921620186144577],[-0.3714455823762248,-0.053642815639504335,-0.5038778370896142,-0.4399335061373562,-0.16680064211583787,1.0,0.35241543015455323,0.08046640939583319,0.055705382613134645],[-0.8297177868014962,-0.0398962975158734,-0.5423318661691973,-0.5150923288475668,-0.1014191620112754,0.35241543015455323,1.0,0.06324049001061859,0.1242685770981546],[-0.05985545294237017,0.00039422357639061804,-0.36793452672531024,-0.3492748053692272,-0.16251006101732512,0.08046640939583319,0.06324049001061859,1.0,-0.050315527841782205],[-0.081191957347104,-0.18210355920226182,-0.08387745431547668,0.007089428962942723,0.08921620186144577,0.055705382613134645,0.1242685770981546,-0.050315527841782205,1.0]],\"type\":\"heatmap\"}],                        {\"annotations\":[{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"Car_Name\",\"xref\":\"x\",\"y\":\"Car_Name\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.02\",\"x\":\"Year\",\"xref\":\"x\",\"y\":\"Car_Name\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.49\",\"x\":\"Selling_Price\",\"xref\":\"x\",\"y\":\"Car_Name\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.48\",\"x\":\"Present_Price\",\"xref\":\"x\",\"y\":\"Car_Name\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.06\",\"x\":\"Kms_Driven\",\"xref\":\"x\",\"y\":\"Car_Name\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.37\",\"x\":\"Fuel_Type\",\"xref\":\"x\",\"y\":\"Car_Name\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.83\",\"x\":\"Seller_Type\",\"xref\":\"x\",\"y\":\"Car_Name\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.06\",\"x\":\"Transmission\",\"xref\":\"x\",\"y\":\"Car_Name\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.08\",\"x\":\"Owner\",\"xref\":\"x\",\"y\":\"Car_Name\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.02\",\"x\":\"Car_Name\",\"xref\":\"x\",\"y\":\"Year\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"Year\",\"xref\":\"x\",\"y\":\"Year\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.23\",\"x\":\"Selling_Price\",\"xref\":\"x\",\"y\":\"Year\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.05\",\"x\":\"Present_Price\",\"xref\":\"x\",\"y\":\"Year\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.52\",\"x\":\"Kms_Driven\",\"xref\":\"x\",\"y\":\"Year\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.05\",\"x\":\"Fuel_Type\",\"xref\":\"x\",\"y\":\"Year\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.04\",\"x\":\"Seller_Type\",\"xref\":\"x\",\"y\":\"Year\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0\",\"x\":\"Transmission\",\"xref\":\"x\",\"y\":\"Year\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.18\",\"x\":\"Owner\",\"xref\":\"x\",\"y\":\"Year\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.49\",\"x\":\"Car_Name\",\"xref\":\"x\",\"y\":\"Selling_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.23\",\"x\":\"Year\",\"xref\":\"x\",\"y\":\"Selling_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"Selling_Price\",\"xref\":\"x\",\"y\":\"Selling_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.88\",\"x\":\"Present_Price\",\"xref\":\"x\",\"y\":\"Selling_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.03\",\"x\":\"Kms_Driven\",\"xref\":\"x\",\"y\":\"Selling_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.5\",\"x\":\"Fuel_Type\",\"xref\":\"x\",\"y\":\"Selling_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.54\",\"x\":\"Seller_Type\",\"xref\":\"x\",\"y\":\"Selling_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.37\",\"x\":\"Transmission\",\"xref\":\"x\",\"y\":\"Selling_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.08\",\"x\":\"Owner\",\"xref\":\"x\",\"y\":\"Selling_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.48\",\"x\":\"Car_Name\",\"xref\":\"x\",\"y\":\"Present_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.05\",\"x\":\"Year\",\"xref\":\"x\",\"y\":\"Present_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.88\",\"x\":\"Selling_Price\",\"xref\":\"x\",\"y\":\"Present_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"Present_Price\",\"xref\":\"x\",\"y\":\"Present_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.21\",\"x\":\"Kms_Driven\",\"xref\":\"x\",\"y\":\"Present_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.44\",\"x\":\"Fuel_Type\",\"xref\":\"x\",\"y\":\"Present_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.52\",\"x\":\"Seller_Type\",\"xref\":\"x\",\"y\":\"Present_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.35\",\"x\":\"Transmission\",\"xref\":\"x\",\"y\":\"Present_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.01\",\"x\":\"Owner\",\"xref\":\"x\",\"y\":\"Present_Price\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.06\",\"x\":\"Car_Name\",\"xref\":\"x\",\"y\":\"Kms_Driven\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.52\",\"x\":\"Year\",\"xref\":\"x\",\"y\":\"Kms_Driven\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.03\",\"x\":\"Selling_Price\",\"xref\":\"x\",\"y\":\"Kms_Driven\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.21\",\"x\":\"Present_Price\",\"xref\":\"x\",\"y\":\"Kms_Driven\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"Kms_Driven\",\"xref\":\"x\",\"y\":\"Kms_Driven\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.17\",\"x\":\"Fuel_Type\",\"xref\":\"x\",\"y\":\"Kms_Driven\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1\",\"x\":\"Seller_Type\",\"xref\":\"x\",\"y\":\"Kms_Driven\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.16\",\"x\":\"Transmission\",\"xref\":\"x\",\"y\":\"Kms_Driven\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.09\",\"x\":\"Owner\",\"xref\":\"x\",\"y\":\"Kms_Driven\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.37\",\"x\":\"Car_Name\",\"xref\":\"x\",\"y\":\"Fuel_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.05\",\"x\":\"Year\",\"xref\":\"x\",\"y\":\"Fuel_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.5\",\"x\":\"Selling_Price\",\"xref\":\"x\",\"y\":\"Fuel_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.44\",\"x\":\"Present_Price\",\"xref\":\"x\",\"y\":\"Fuel_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.17\",\"x\":\"Kms_Driven\",\"xref\":\"x\",\"y\":\"Fuel_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"Fuel_Type\",\"xref\":\"x\",\"y\":\"Fuel_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.35\",\"x\":\"Seller_Type\",\"xref\":\"x\",\"y\":\"Fuel_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.08\",\"x\":\"Transmission\",\"xref\":\"x\",\"y\":\"Fuel_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.06\",\"x\":\"Owner\",\"xref\":\"x\",\"y\":\"Fuel_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.83\",\"x\":\"Car_Name\",\"xref\":\"x\",\"y\":\"Seller_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.04\",\"x\":\"Year\",\"xref\":\"x\",\"y\":\"Seller_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.54\",\"x\":\"Selling_Price\",\"xref\":\"x\",\"y\":\"Seller_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.52\",\"x\":\"Present_Price\",\"xref\":\"x\",\"y\":\"Seller_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1\",\"x\":\"Kms_Driven\",\"xref\":\"x\",\"y\":\"Seller_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.35\",\"x\":\"Fuel_Type\",\"xref\":\"x\",\"y\":\"Seller_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"Seller_Type\",\"xref\":\"x\",\"y\":\"Seller_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.06\",\"x\":\"Transmission\",\"xref\":\"x\",\"y\":\"Seller_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.12\",\"x\":\"Owner\",\"xref\":\"x\",\"y\":\"Seller_Type\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.06\",\"x\":\"Car_Name\",\"xref\":\"x\",\"y\":\"Transmission\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0\",\"x\":\"Year\",\"xref\":\"x\",\"y\":\"Transmission\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.37\",\"x\":\"Selling_Price\",\"xref\":\"x\",\"y\":\"Transmission\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.35\",\"x\":\"Present_Price\",\"xref\":\"x\",\"y\":\"Transmission\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.16\",\"x\":\"Kms_Driven\",\"xref\":\"x\",\"y\":\"Transmission\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.08\",\"x\":\"Fuel_Type\",\"xref\":\"x\",\"y\":\"Transmission\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.06\",\"x\":\"Seller_Type\",\"xref\":\"x\",\"y\":\"Transmission\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"Transmission\",\"xref\":\"x\",\"y\":\"Transmission\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.05\",\"x\":\"Owner\",\"xref\":\"x\",\"y\":\"Transmission\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.08\",\"x\":\"Car_Name\",\"xref\":\"x\",\"y\":\"Owner\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.18\",\"x\":\"Year\",\"xref\":\"x\",\"y\":\"Owner\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.08\",\"x\":\"Selling_Price\",\"xref\":\"x\",\"y\":\"Owner\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.01\",\"x\":\"Present_Price\",\"xref\":\"x\",\"y\":\"Owner\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.09\",\"x\":\"Kms_Driven\",\"xref\":\"x\",\"y\":\"Owner\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.06\",\"x\":\"Fuel_Type\",\"xref\":\"x\",\"y\":\"Owner\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.12\",\"x\":\"Seller_Type\",\"xref\":\"x\",\"y\":\"Owner\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.05\",\"x\":\"Transmission\",\"xref\":\"x\",\"y\":\"Owner\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"Owner\",\"xref\":\"x\",\"y\":\"Owner\",\"yref\":\"y\"}],\"xaxis\":{\"dtick\":1,\"gridcolor\":\"rgb(0, 0, 0)\",\"side\":\"top\",\"ticks\":\"\"},\"yaxis\":{\"dtick\":1,\"ticks\":\"\",\"ticksuffix\":\"  \"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"title\":{\"text\":\"Correlation matrix with rounded numbers in size 10x10\"},\"width\":1000,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('a025eaee-acc1-4308-9662-49ecf7b860d8');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation matrix\n",
    "corrmat = train0.corr()\n",
    "fig = ff.create_annotated_heatmap(z=corrmat.values, x=list(corrmat.columns), y=list(corrmat.index), annotation_text=corrmat.round(2).values, colorscale='tropic')\n",
    "fig.update_layout(title_text='Correlation matrix with rounded numbers in size 10x10', width=1000, height=600)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:05.951406Z",
     "start_time": "2023-05-24T13:21:05.895915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "         Car_Name        Year  Selling_Price  Present_Price     Kms_Driven   \ncount  301.000000  301.000000     301.000000     301.000000     301.000000  \\\nmean    62.571429  113.627907       4.215947       7.033223   36947.205980   \nstd     25.573535    2.891554       5.098681       8.663654   38886.883882   \nmin      0.000000  103.000000       0.000000       0.000000     500.000000   \n25%     47.000000  112.000000       0.000000       1.000000   15000.000000   \n50%     69.000000  114.000000       3.000000       6.000000   32000.000000   \n75%     82.000000  116.000000       6.000000       9.000000   48767.000000   \nmax     97.000000  118.000000      35.000000      92.000000  500000.000000   \n\n        Fuel_Type  Seller_Type  Transmission       Owner  \ncount  301.000000   301.000000    301.000000  301.000000  \nmean     1.787375     0.352159      0.867110    0.043189  \nstd      0.425801     0.478439      0.340021    0.247915  \nmin      0.000000     0.000000      0.000000    0.000000  \n25%      2.000000     0.000000      1.000000    0.000000  \n50%      2.000000     0.000000      1.000000    0.000000  \n75%      2.000000     1.000000      1.000000    0.000000  \nmax      2.000000     1.000000      1.000000    3.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Car_Name</th>\n      <th>Year</th>\n      <th>Selling_Price</th>\n      <th>Present_Price</th>\n      <th>Kms_Driven</th>\n      <th>Fuel_Type</th>\n      <th>Seller_Type</th>\n      <th>Transmission</th>\n      <th>Owner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>301.000000</td>\n      <td>301.000000</td>\n      <td>301.000000</td>\n      <td>301.000000</td>\n      <td>301.000000</td>\n      <td>301.000000</td>\n      <td>301.000000</td>\n      <td>301.000000</td>\n      <td>301.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>62.571429</td>\n      <td>113.627907</td>\n      <td>4.215947</td>\n      <td>7.033223</td>\n      <td>36947.205980</td>\n      <td>1.787375</td>\n      <td>0.352159</td>\n      <td>0.867110</td>\n      <td>0.043189</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>25.573535</td>\n      <td>2.891554</td>\n      <td>5.098681</td>\n      <td>8.663654</td>\n      <td>38886.883882</td>\n      <td>0.425801</td>\n      <td>0.478439</td>\n      <td>0.340021</td>\n      <td>0.247915</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>103.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>500.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>47.000000</td>\n      <td>112.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>15000.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>69.000000</td>\n      <td>114.000000</td>\n      <td>3.000000</td>\n      <td>6.000000</td>\n      <td>32000.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>82.000000</td>\n      <td>116.000000</td>\n      <td>6.000000</td>\n      <td>9.000000</td>\n      <td>48767.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>97.000000</td>\n      <td>118.000000</td>\n      <td>35.000000</td>\n      <td>92.000000</td>\n      <td>500000.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train0.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:06.968536Z",
     "start_time": "2023-05-24T13:21:06.916126Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **2.2. Summary Report**\n",
    "The summary report delivers a quick overview of the data. It is a great way to get a quick overview of the data and to identify potential problems. The report is generated using the ydata_profiling library."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train0 = train0.dropna()\n",
    "# pp.ProfileReport(train0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:08.787794Z",
     "start_time": "2023-05-24T13:21:08.762792Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "target_name = 'Selling_Price'\n",
    "train_target0 = train0[target_name]\n",
    "train0 = train0.drop([target_name], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:09.661462Z",
     "start_time": "2023-05-24T13:21:09.649974Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Synthesis test0 from train0\n",
    "train0, test0, train_target0, test_target0 = train_test_split(train0, train_target0, test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:10.442617Z",
     "start_time": "2023-05-24T13:21:10.431264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# For boosting model\n",
    "train0b = train0\n",
    "train_target0b = train_target0\n",
    "# Synthesis valid as test for selection models\n",
    "trainb, testb, targetb, target_testb = train_test_split(train0b, train_target0b, test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:11.064973Z",
     "start_time": "2023-05-24T13:21:11.055533Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#For models from Sklearn\n",
    "scaler = StandardScaler()\n",
    "train0 = pd.DataFrame(scaler.fit_transform(train0), columns = train0.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:11.868708Z",
     "start_time": "2023-05-24T13:21:11.860988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   Car_Name      Year  Present_Price  Kms_Driven  Fuel_Type  Seller_Type   \n0  0.598144  0.147092       0.108990    1.057060  -1.880246    -0.754074  \\\n1  0.519998 -0.531795      -0.336246   -0.352927   0.482367    -0.754074   \n2  0.754436  1.165424       3.225646   -0.774061  -1.880246    -0.754074   \n\n   Transmission     Owner  \n0      0.370730 -0.139347  \n1      0.370730 -0.139347  \n2     -2.697381 -0.139347  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Car_Name</th>\n      <th>Year</th>\n      <th>Present_Price</th>\n      <th>Kms_Driven</th>\n      <th>Fuel_Type</th>\n      <th>Seller_Type</th>\n      <th>Transmission</th>\n      <th>Owner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.598144</td>\n      <td>0.147092</td>\n      <td>0.108990</td>\n      <td>1.057060</td>\n      <td>-1.880246</td>\n      <td>-0.754074</td>\n      <td>0.370730</td>\n      <td>-0.139347</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.519998</td>\n      <td>-0.531795</td>\n      <td>-0.336246</td>\n      <td>-0.352927</td>\n      <td>0.482367</td>\n      <td>-0.754074</td>\n      <td>0.370730</td>\n      <td>-0.139347</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.754436</td>\n      <td>1.165424</td>\n      <td>3.225646</td>\n      <td>-0.774061</td>\n      <td>-1.880246</td>\n      <td>-0.754074</td>\n      <td>-2.697381</td>\n      <td>-0.139347</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train0.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:12.584950Z",
     "start_time": "2023-05-24T13:21:12.567853Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "240"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:13.319194Z",
     "start_time": "2023-05-24T13:21:13.288810Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Synthesis valid as test for selection models\n",
    "train, test, target, target_test = train_test_split(train0, train_target0, test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:14.019196Z",
     "start_time": "2023-05-24T13:21:14.009485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "     Car_Name      Year  Present_Price  Kms_Driven  Fuel_Type  Seller_Type   \n110  0.871655 -0.871239      -0.113628   -0.165177   0.482367    -0.754074  \\\n239 -1.902534  0.147092      -0.781483   -0.590949   0.482367     1.326130   \n63  -1.433657  0.486536      -0.781483   -0.757414   0.482367     1.326130   \n\n     Transmission     Owner  \n110       0.37073 -0.139347  \n239       0.37073 -0.139347  \n63        0.37073 -0.139347  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Car_Name</th>\n      <th>Year</th>\n      <th>Present_Price</th>\n      <th>Kms_Driven</th>\n      <th>Fuel_Type</th>\n      <th>Seller_Type</th>\n      <th>Transmission</th>\n      <th>Owner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>110</th>\n      <td>0.871655</td>\n      <td>-0.871239</td>\n      <td>-0.113628</td>\n      <td>-0.165177</td>\n      <td>0.482367</td>\n      <td>-0.754074</td>\n      <td>0.37073</td>\n      <td>-0.139347</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>-1.902534</td>\n      <td>0.147092</td>\n      <td>-0.781483</td>\n      <td>-0.590949</td>\n      <td>0.482367</td>\n      <td>1.326130</td>\n      <td>0.37073</td>\n      <td>-0.139347</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>-1.433657</td>\n      <td>0.486536</td>\n      <td>-0.781483</td>\n      <td>-0.757414</td>\n      <td>0.482367</td>\n      <td>1.326130</td>\n      <td>0.37073</td>\n      <td>-0.139347</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:14.588909Z",
     "start_time": "2023-05-24T13:21:14.581889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "     Car_Name      Year  Present_Price  Kms_Driven  Fuel_Type  Seller_Type   \n109  0.754436 -0.531795       2.557791    1.573270  -1.880246    -0.754074  \\\n71   0.949802  0.825980       2.001245   -0.227103  -1.880246    -0.754074   \n37  -1.980680  1.165424      -0.670174   -0.888209   0.482367     1.326130   \n\n     Transmission     Owner  \n109     -2.697381 -0.139347  \n71      -2.697381 -0.139347  \n37       0.370730 -0.139347  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Car_Name</th>\n      <th>Year</th>\n      <th>Present_Price</th>\n      <th>Kms_Driven</th>\n      <th>Fuel_Type</th>\n      <th>Seller_Type</th>\n      <th>Transmission</th>\n      <th>Owner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>109</th>\n      <td>0.754436</td>\n      <td>-0.531795</td>\n      <td>2.557791</td>\n      <td>1.573270</td>\n      <td>-1.880246</td>\n      <td>-0.754074</td>\n      <td>-2.697381</td>\n      <td>-0.139347</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.949802</td>\n      <td>0.825980</td>\n      <td>2.001245</td>\n      <td>-0.227103</td>\n      <td>-1.880246</td>\n      <td>-0.754074</td>\n      <td>-2.697381</td>\n      <td>-0.139347</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>-1.980680</td>\n      <td>1.165424</td>\n      <td>-0.670174</td>\n      <td>-0.888209</td>\n      <td>0.482367</td>\n      <td>1.326130</td>\n      <td>0.370730</td>\n      <td>-0.139347</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:15.319060Z",
     "start_time": "2023-05-24T13:21:15.301062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 192 entries, 110 to 172\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Car_Name       192 non-null    float64\n",
      " 1   Year           192 non-null    float64\n",
      " 2   Present_Price  192 non-null    float64\n",
      " 3   Kms_Driven     192 non-null    float64\n",
      " 4   Fuel_Type      192 non-null    float64\n",
      " 5   Seller_Type    192 non-null    float64\n",
      " 6   Transmission   192 non-null    float64\n",
      " 7   Owner          192 non-null    float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 13.5 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:16.067015Z",
     "start_time": "2023-05-24T13:21:16.051504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 48 entries, 109 to 7\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Car_Name       48 non-null     float64\n",
      " 1   Year           48 non-null     float64\n",
      " 2   Present_Price  48 non-null     float64\n",
      " 3   Kms_Driven     48 non-null     float64\n",
      " 4   Fuel_Type      48 non-null     float64\n",
      " 5   Seller_Type    48 non-null     float64\n",
      " 6   Transmission   48 non-null     float64\n",
      " 7   Owner          48 non-null     float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 3.4 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:16.867549Z",
     "start_time": "2023-05-24T13:21:16.848773Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "acc_train_r2 = []\n",
    "acc_test_r2 = []\n",
    "acc_train_d = []\n",
    "acc_test_d = []\n",
    "acc_train_rmse = []\n",
    "acc_test_rmse = []\n",
    "acc_train_mae = []\n",
    "acc_test_mae = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:17.822166Z",
     "start_time": "2023-05-24T13:21:17.812148Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **2.3 Model Functions**\n",
    "Packing our model functions in a single function allows us to easily call them later for multiple models. We will use the following functions:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def acc_d(y_meas, y_pred):\n",
    "    # Relative error between predicted y_pred and measured y_meas values\n",
    "    return mean_absolute_error(y_meas, y_pred)*len(y_meas)/sum(abs(y_meas))\n",
    "\n",
    "def acc_rmse(y_meas, y_pred):\n",
    "    # RMSE between predicted y_pred and measured y_meas values\n",
    "    return (mean_squared_error(y_meas, y_pred))**0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:19.341851Z",
     "start_time": "2023-05-24T13:21:19.325537Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def acc_boosting_model(num,model,train,test,num_iteration=0):\n",
    "    # Calculation of accuracy of boosting model by different metrics\n",
    "\n",
    "    global acc_train_r2, acc_test_r2, acc_train_d, acc_test_d, acc_train_rmse, acc_test_rmse, acc_train_mae, acc_test_mae\n",
    "\n",
    "    if num_iteration > 0:\n",
    "        ytrain = model.predict(train, num_iteration = num_iteration)\n",
    "        ytest = model.predict(test, num_iteration = num_iteration)\n",
    "    else:\n",
    "        ytrain = model.predict(train)\n",
    "        ytest = model.predict(test)\n",
    "\n",
    "    print('target = ', targetb[:5].values)\n",
    "    print('ytrain = ', ytrain[:5])\n",
    "\n",
    "    acc_train_r2_num = round(r2_score(targetb, ytrain) * 100, 2)\n",
    "    print('acc(r2_score) for train =', acc_train_r2_num)\n",
    "    acc_train_r2.insert(num, acc_train_r2_num)\n",
    "\n",
    "    acc_train_d_num = round(acc_d(targetb, ytrain) * 100, 2)\n",
    "    print('acc(relative error) for train =', acc_train_d_num)\n",
    "    acc_train_d.insert(num, acc_train_d_num)\n",
    "\n",
    "    acc_train_rmse_num = round(acc_rmse(targetb, ytrain) * 100, 2)\n",
    "    print('acc(rmse) for train =', acc_train_rmse_num)\n",
    "    acc_train_rmse.insert(num, acc_train_rmse_num)\n",
    "\n",
    "    acc_train_mae_num = round(mean_absolute_error(targetb, ytrain) * 100, 2)\n",
    "    print('acc(mae) for train =', acc_train_mae_num)\n",
    "    acc_train_mae.insert(num, acc_train_mae_num)\n",
    "\n",
    "    print('target_test =', target_testb[:5].values)\n",
    "    print('ytest =', ytest[:5])\n",
    "\n",
    "    acc_test_r2_num = round(r2_score(target_testb, ytest) * 100, 2)\n",
    "    print('acc(r2_score) for test =', acc_test_r2_num)\n",
    "    acc_test_r2.insert(num, acc_test_r2_num)\n",
    "\n",
    "    acc_test_d_num = round(acc_d(target_testb, ytest) * 100, 2)\n",
    "    print('acc(relative error) for test =', acc_test_d_num)\n",
    "    acc_test_d.insert(num, acc_test_d_num)\n",
    "\n",
    "    acc_test_rmse_num = round(acc_rmse(target_testb, ytest) * 100, 2)\n",
    "    print('acc(rmse) for test =', acc_test_rmse_num)\n",
    "    acc_test_rmse.insert(num, acc_test_rmse_num)\n",
    "\n",
    "    acc_test_mae_num = round(mean_absolute_error(target_testb, ytest) * 100, 2)\n",
    "    print('acc(mae) for test =', acc_test_mae_num)\n",
    "    acc_test_mae.insert(num, acc_test_mae_num)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:20.194376Z",
     "start_time": "2023-05-24T13:21:20.187609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def acc_model(num,model,train,test):\n",
    "    # Calculation of accuracy of model  Sklearn by different metrics\n",
    "\n",
    "    global acc_train_r2, acc_test_r2, acc_train_d, acc_test_d, acc_train_rmse, acc_test_rmse, acc_train_mae, acc_test_mae\n",
    "\n",
    "    ytrain = model.predict(train)\n",
    "    ytest = model.predict(test)\n",
    "\n",
    "    print('target = ', target[:5].values)\n",
    "    print('ytrain = ', ytrain[:5])\n",
    "\n",
    "    acc_train_r2_num = round(r2_score(target, ytrain) * 100, 2)\n",
    "    print('acc(r2_score) for train =', acc_train_r2_num)\n",
    "    acc_train_r2.insert(num, acc_train_r2_num)\n",
    "\n",
    "    acc_train_d_num = round(acc_d(target, ytrain) * 100, 2)\n",
    "    print('acc(relative error) for train =', acc_train_d_num)\n",
    "    acc_train_d.insert(num, acc_train_d_num)\n",
    "\n",
    "    acc_train_rmse_num = round(acc_rmse(target, ytrain) * 100, 2)\n",
    "    print('acc(rmse) for train =', acc_train_rmse_num)\n",
    "    acc_train_rmse.insert(num, acc_train_rmse_num)\n",
    "\n",
    "    acc_train_mae_num = round(mean_absolute_error(target, ytrain) * 100, 2)\n",
    "    print('acc(mae) for train =', acc_train_mae_num)\n",
    "    acc_train_mae.insert(num, acc_train_mae_num)\n",
    "\n",
    "    print('target_test =', target_test[:5].values)\n",
    "    print('ytest =', ytest[:5])\n",
    "\n",
    "    acc_test_r2_num = round(r2_score(target_test, ytest) * 100, 2)\n",
    "    print('acc(r2_score) for test =', acc_test_r2_num)\n",
    "    acc_test_r2.insert(num, acc_test_r2_num)\n",
    "\n",
    "    acc_test_d_num = round(acc_d(target_test, ytest) * 100, 2)\n",
    "    print('acc(relative error) for test =', acc_test_d_num)\n",
    "    acc_test_d.insert(num, acc_test_d_num)\n",
    "\n",
    "    acc_test_rmse_num = round(acc_rmse(target_test, ytest) * 100, 2)\n",
    "    print('acc(rmse) for test =', acc_test_rmse_num)\n",
    "    acc_test_rmse.insert(num, acc_test_rmse_num)\n",
    "\n",
    "    acc_test_mae_num = round(mean_absolute_error(target_test, ytest) * 100, 2)\n",
    "    print('acc(mae) for test =', acc_test_mae_num)\n",
    "    acc_test_mae.insert(num, acc_test_mae_num)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:21.620351Z",
     "start_time": "2023-05-24T13:21:21.610553Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Model Comparison\n",
    "Now, that we have prepared our data and defined our functions, we can start to compare different models. We will use the above modelsnamed in the outline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Linear Regression\n",
    "Linear Regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression. Reference Wikipedia.\n",
    "\n",
    "Note the confidence score generated by the model based on our training dataset.\n",
    "\n",
    "Model Improvement:\n",
    "1. Feature Selection: Choose the most important features that have a high correlation with the target variable. Removing unnecessary or irrelevant features can improve the model's performance.\n",
    "\n",
    "2. Data Cleaning: Remove outliers, missing values, and duplicates that can influence the model's accuracy.\n",
    "\n",
    "3. Normalization: Normalizing the data can improve the model's performance by reducing the effect of large or small values.\n",
    "\n",
    "4. Regularization: Regularization techniques such as L1 and L2 can help to reduce overfitting by adding a penalty term to the cost function.\n",
    "\n",
    "5. Bias-Variance tradeoff: Balancing model bias and variance can help to improve the model's performance by reducing underfitting and overfitting.\n",
    "\n",
    "6. Cross-validation: Use cross-validation techniques to estimate the model's performance and avoid overfitting.\n",
    "\n",
    "7. Hyperparameter tuning: Experiment with different hyperparameters such as learning rates and regularization parameters to find the optimal values that improve the model's performance.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [2.64426551 0.49514931 0.83348214 0.87416613 6.57241738]\n",
      "acc(r2_score) for train = 86.53\n",
      "acc(relative error) for train = 30.5\n",
      "acc(rmse) for train = 187.52\n",
      "acc(mae) for train = 126.29\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [16.60386604 16.41219025  2.1424285   9.64345065  3.77632914]\n",
      "acc(r2_score) for test = 82.07\n",
      "acc(relative error) for test = 42.93\n",
      "acc(rmse) for test = 214.93\n",
      "acc(mae) for test = 164.57\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(train, target)\n",
    "acc_model(0,linreg,train,test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:24.346438Z",
     "start_time": "2023-05-24T13:21:24.327613Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression with Bagging\n",
    "# Get params for Linear Regression\n",
    "params = linreg.get_params()\n",
    "params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:25.313314Z",
     "start_time": "2023-05-24T13:21:25.295195Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': True}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression Grid Search\n",
    "# Create the parameter grid based on the results of random search\n",
    "parameters = {\n",
    "    'copy_X': [True, False],\n",
    "    'fit_intercept': [True, False],\n",
    "    'positive': [True, False],\n",
    "    'n_jobs': [-1, 1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=linreg, param_grid=parameters, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(train, target)\n",
    "grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:21:28.461632Z",
     "start_time": "2023-05-24T13:21:26.116154Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Support Vector Machines\n",
    "Support Vector Machines are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training samples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new test samples to one category or the other, making it a non-probabilistic binary linear classifier. Obtained from Wikipedia.\n",
    "\n",
    "Model Improvement:\n",
    "1. Choosing optimal parameters: SVMs have several parameters such as the regularization parameter (C), kernel function, kernel parameters, and gamma parameter. Choosing the optimal values for these parameters can improve the performance of SVMs.\n",
    "\n",
    "2. Feature selection: Feature selection can help to reduce the dimensionality of the data and focus on the most relevant features. This can improve the performance of SVMs by reducing overfitting.\n",
    "\n",
    "3. Choosing the right kernel function: SVMs use kernel functions to map the data into a higher-dimensional space. Choosing the right kernel function can improve the performance of SVMs.\n",
    "\n",
    "4. Data preprocessing: Data preprocessing techniques such as normalization, scaling, and outlier removal can help to improve the performance of SVMs.\n",
    "\n",
    "5. Using ensemble methods: Ensemble methods such as bagging and boosting can improve the performance of SVMs by building multiple classifiers and combining their predictions.\n",
    "\n",
    "6. Using kernel methods: Kernel methods such as linear SVM and kernel ridge regression can improve the performance of SVMs by providing a better way of handling linear and nonlinear relationships between variables.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [ 2.50442859 -0.0289507   0.10061086  0.61474311  6.00538421]\n",
      "acc(r2_score) for train = 48.61\n",
      "acc(relative error) for train = 31.39\n",
      "acc(rmse) for train = 366.3\n",
      "acc(mae) for train = 129.99\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [7.26926331 8.78543825 0.34673698 5.98769573 0.46354626]\n",
      "acc(r2_score) for test = 63.97\n",
      "acc(relative error) for test = 36.2\n",
      "acc(rmse) for test = 304.66\n",
      "acc(mae) for test = 138.75\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(train, target)\n",
    "acc_model(1,svr,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch for Linear SVR\n",
    "\n",
    "parameters = {'C': [0.1, 1, 10, 100], 'gamma': [10, 1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}\n",
    "grid = GridSearchCV(SVR(), parameters, refit=True, verbose=2)\n",
    "grid.fit(train, target)\n",
    "grid.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Linear Support Vector Regression\n",
    "Linear SVR is a similar to SVM method. Its also builds on kernel functions but is appropriate for unsupervised learning. Reference Wikipedia.\n",
    "\n",
    "Model Improvement:\n",
    "1. Feature engineering: By selecting the right set of features or transforming them, one can improve the accuracy of the model significantly. This involves identifying the relevant features and removing irrelevant ones as well as creating new composite features that capture the underlying patterns in the data.\n",
    "\n",
    "2. Regularization: By adding regularization terms to the objective function, one can prevent overfitting and improve the generalization of the model. A popular approach is to add L1 or L2 regularization terms, which encourage the coefficients to be small.\n",
    "\n",
    "3. Hyperparameter tuning: Linear SVR has several hyperparameters such as the regularization parameter, kernel parameter, and penalty term, that can be fine-tuned to improve the performance of the model. Grid search or randomized search can be used to find the optimal hyperparameters.\n",
    "\n",
    "4. Scaling inputs: Since Linear SVR uses a distance metric to measure similarity between data points, it is sensitive to the scale of the input features. By scaling the input features to a common range, Linear SVR can perform better and converge faster.\n",
    "\n",
    "5. Collecting more data: When there is insufficient data, the model may not generalize well. Collecting more data of the right quality can lead to a more reliable and robust model.\n",
    "\n",
    "6. Use a non-linear model: If the relationship between the input features and target variable is non-linear, a non-linear SVR algorithm such as RBF kernel can be used to improve the performance.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [2.97532147 0.2284961  0.41958991 0.42128161 5.34079231]\n",
      "acc(r2_score) for train = 83.77\n",
      "acc(relative error) for train = 27.75\n",
      "acc(rmse) for train = 205.85\n",
      "acc(mae) for train = 114.9\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [15.22096721 14.13512563  1.41598373  9.43410964  1.86992038]\n",
      "acc(r2_score) for test = 84.15\n",
      "acc(relative error) for test = 36.12\n",
      "acc(rmse) for test = 202.05\n",
      "acc(mae) for test = 138.47\n"
     ]
    }
   ],
   "source": [
    "# Linear SVR\n",
    "\n",
    "linear_svr = LinearSVR()\n",
    "linear_svr.fit(train, target)\n",
    "acc_model(2,linear_svr,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 1, 'max_iter': 10000}"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch for Linear SVR\n",
    "\n",
    "linear_svr = LinearSVR()\n",
    "parameters = {'C': [0.01, 0.1, 1, 10, 100, 1000], 'max_iter': [1000, 10000]}\n",
    "\n",
    "clf = GridSearchCV(linear_svr, parameters, cv=5)\n",
    "clf.fit(train, target)\n",
    "clf.best_params_\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4 MLP Regressor\n",
    "MLPRegressor is a multi-layer Perceptron regressor. This model optimizes the squared-loss using LBFGS or stochastic gradient descent. Reference Scikit-learn.\n",
    "\n",
    "Model Improvement:\n",
    "1. Feature engineering: Feature engineering is the process of selecting and transforming relevant variables in your dataset to improve model performance. Look for variables that have a strong relationship with your target variable and engineer new variables by combining or transforming existing variables.\n",
    "\n",
    "2. Model architecture: Change the architecture of your MLP Regressor. This includes increasing the number of layers, neurons, and tuning the activation function.\n",
    "\n",
    "3. Regularization: Regularization is a technique used to reduce overfitting by adding a penalty term to the loss function. L1 and L2 regularization can be used to prevent overfitting.\n",
    "\n",
    "4. Hyperparameter optimization: Hyperparameters are the variables that control the behavior of the model. Tune the hyperparameters of the MLP Regressor, such as the learning rate, batch size, number of epochs, etc. to improve model performance.\n",
    "\n",
    "5. Data preprocessing: Preprocess your data by scaling or normalizing it, and dealing with missing or outlier values. This can help improve model performance.\n",
    "\n",
    "6. Ensemble learning: Ensemble learning involves combining multiple models to make more accurate predictions. Consider using a combination of MLP Regressors or other models to improve overall performance.\n",
    "\n",
    "7. Increase training data: Ensure you have enough training data to train and validate the model effectively. Increasing the amount of training data will help the model learn better patterns and relationships.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [3.13541036 0.12141531 0.36879656 1.00992005 6.24039399]\n",
      "acc(r2_score) for train = 87.88\n",
      "acc(relative error) for train = 29.94\n",
      "acc(rmse) for train = 177.86\n",
      "acc(mae) for train = 123.97\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [17.37889276 19.03160785  0.43155143  8.20112166  1.69732631]\n",
      "acc(r2_score) for test = 86.05\n",
      "acc(relative error) for test = 32.42\n",
      "acc(rmse) for test = 189.55\n",
      "acc(mae) for test = 124.28\n"
     ]
    }
   ],
   "source": [
    "# MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "param_grid = {'hidden_layer_sizes': [i for i in range(2,20)],\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['adam'],\n",
    "              'learning_rate': ['constant'],\n",
    "              'learning_rate_init': [0.01],\n",
    "              'power_t': [0.5],\n",
    "              'alpha': [0.0001],\n",
    "              'max_iter': [1000],\n",
    "              'early_stopping': [True],\n",
    "              'warm_start': [False]}\n",
    "mlp_GS = GridSearchCV(mlp, param_grid=param_grid,\n",
    "                      cv=10, verbose=True, pre_dispatch='2*n_jobs')\n",
    "mlp_GS.fit(train, target)\n",
    "acc_model(3,mlp_GS,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'activation': 'relu',\n 'alpha': 0.0001,\n 'hidden_layer_sizes': (10, 30, 10),\n 'learning_rate': 'constant',\n 'solver': 'sgd'}"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch for MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor(max_iter=100)\n",
    "\n",
    "parameter = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "mlp_GS = GridSearchCV(mlp, parameter, cv=10, verbose=True, pre_dispatch='2*n_jobs')\n",
    "mlp_GS.fit(train, target)\n",
    "mlp_GS.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.5 Stochastic Gradient Descent\n",
    "Stochastic gradient descent (often shortened to SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Reference Wikipedia.\n",
    "\n",
    "Model Improvement:\n",
    "1. Use a smaller learning rate: Stochastic Gradient Descent (SGD) can become unstable if the learning rate is too large. Reducing the learning rate can make the algorithm converge more slowly but it can prevent it from overshooting the optimal solution or getting trapped in poor local minima.\n",
    "\n",
    "2. Increase the batch size: By increasing the batch size, you can get better and more stable updates to the weights. Larger batches can help smooth out the noise in the gradients, which can make the convergence more steady.\n",
    "\n",
    "3. Implement better initialization techniques: Proper initialization of the models parameters can significantly improve the optimization process of the algorithm. Some techniques include Xavier Initialization or variations of it, He Initialization or Batch Normalization.\n",
    "\n",
    "4. Regularize the model: Regularization techniques like L1 or L2 regularization or Dropout can help to prevent overfitting, which can help to prevent the model from becoming unstable and avoid getting stuck in poor local minima.\n",
    "\n",
    "5. Use adaptive learning rate methods such as Adam or RMSprop which adjusts the learning rate dynamically based on the estimated second moment of the gradient, and thus can handle varying gradient magnitudes more effectively.\n",
    "\n",
    "6. Train for more epochs: By training the model for more epochs, the algorithm has more time to learn the underlying patterns in the data and provides more stable convergence. It is important to stop the training at an appropriate time though in order to avoid overfitting.\n",
    "\n",
    "By following the above tips, you can significantly improve the performance of a Stochastic Gradient Descent algorithm.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [2.64748499 0.43895775 0.81075472 0.93583095 6.56794136]\n",
      "acc(r2_score) for train = 86.53\n",
      "acc(relative error) for train = 30.63\n",
      "acc(rmse) for train = 187.57\n",
      "acc(mae) for train = 126.82\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [16.60725345 16.4513307   2.09702845  9.61476803  3.81247281]\n",
      "acc(r2_score) for test = 82.05\n",
      "acc(relative error) for test = 42.94\n",
      "acc(rmse) for test = 215.06\n",
      "acc(mae) for test = 164.6\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(train, target)\n",
    "acc_model(4,sgd,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'alpha': 0.01,\n 'learning_rate': 'constant',\n 'loss': 'epsilon_insensitive',\n 'penalty': 'l2'}"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch\n",
    "parameters = {\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "}\n",
    "grid_search = GridSearchCV(sgd, parameters, cv=10, verbose=True, pre_dispatch='2*n_jobs')\n",
    "grid_search.fit(train, target)\n",
    "grid_search.best_params_\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.6 Descision Tree Regressor\n",
    "This model uses a Decision Tree as a predictive model which maps features (tree branches) to conclusions about the target value (tree leaves). Tree models where the target variable can take a finite set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Reference Wikipedia.\n",
    "\n",
    "Model Improvement:\n",
    "1. Increase the number of trees: Increasing the number of trees in the forest can help improve the model's performance. However, there is a tradeoff between model performance and computational complexity.\n",
    "\n",
    "2. Tune hyperparameters: Hyperparameters such as the number of features to consider when splitting, the maximum depth of the tree, and the minimum number of samples required to split a node can greatly affect the performance of the model. Grid search or random search can be used to find the best hyperparameters.\n",
    "\n",
    "3. Feature selection: Feature selection can help improve the model's performance by removing irrelevant or redundant features. Feature selection methods such as mutual information or recursive feature elimination can be used to identify the most important features.\n",
    "\n",
    "4. Ensemble methods: Ensemble methods such as bagging or boosting can be used to improve the performance of the model. Bagging involves creating multiple models on different subsets of the data, while boosting involves iteratively creating models that focus on the misclassified samples.\n",
    "\n",
    "5. Handling imbalanced data: If the data is imbalanced, meaning one class has significantly more samples than the other, techniques such as oversampling or undersampling can be used to balance the data and improve the performance of the model.\n",
    "\n",
    "6. Preprocessing: Preprocessing the data can also help improve the performance of the model. Techniques such as normalization or scaling can help improve the accuracy of the model by ensuring that all features are on the same scale.\n",
    "\n",
    "7. Regularization: Regularization techniques such as L1 or L2 regularization can help prevent overfitting of the model and improve its generalization performance.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [3.2962963  0.         0.         0.         5.72413793]\n",
      "acc(r2_score) for train = 70.64\n",
      "acc(relative error) for train = 30.9\n",
      "acc(rmse) for train = 276.88\n",
      "acc(mae) for train = 127.94\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [16.26666667 16.26666667  0.77272727 16.26666667  0.        ]\n",
      "acc(r2_score) for test = 64.29\n",
      "acc(relative error) for test = 42.79\n",
      "acc(rmse) for test = 303.32\n",
      "acc(mae) for test = 164.03\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regression\n",
    "# Individual Parameters for Decision Tree\n",
    "param_grid = {'criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "                'splitter': ['best', 'random'],\n",
    "                'max_depth': [i for i in range(2,20)],\n",
    "                'min_samples_split': [i for i in range(2,20)],\n",
    "                'min_samples_leaf': [i for i in range(2,20)],\n",
    "                'min_weight_fraction_leaf': [0.0],\n",
    "                'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "                'random_state': [None],\n",
    "                'max_leaf_nodes': [None],\n",
    "                'min_impurity_decrease': [0.0],\n",
    "                'min_impurity_split': [None],\n",
    "                'presort': [False]}\n",
    "\n",
    "decision_tree = DecisionTreeRegressor(max_depth=4, min_samples_leaf=15, min_samples_split=10)\n",
    "decision_tree.fit(train, target)\n",
    "acc_model(5,decision_tree,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.7 Random Forest\n",
    "Random Forest is one of the most popular model. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators= [100, 300]) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Reference Wikipedia.\n",
    "\n",
    "Model Improvement:\n",
    "1. Increasing the number of trees: Gradient boosting works by combining the predictions of multiple weak learners (i.e., trees). Adding more trees can improve the model's accuracy, but may also increase its complexity and lead to overfitting.\n",
    "\n",
    "2. Tuning the learning rate: The learning rate determines the contribution of each tree to the final prediction. A smaller learning rate results in a more robust model but requires more trees to achieve the same level of accuracy.\n",
    "\n",
    "3. Regularizing the model: Regularization techniques, such as L1/L2 regularization, can help prevent overfitting by penalizing large coefficients. Another option is early stopping, which stops training once the performance on a validation set starts to degrade.\n",
    "\n",
    "4. Addressing missing values: Gradient boosting algorithms cannot handle missing values, so it is important to either impute them or exclude them from the dataset.\n",
    "\n",
    "5. Feature engineering: Feature engineering involves creating new features or transforming existing ones to better capture the underlying patterns in the data. This can help improve model performance by providing more relevant information to the algorithm.\n",
    "\n",
    "6. Using a more advanced algorithm: Gradient boosting is just one of many regression algorithms available. It may be worth exploring other algorithms, such as neural networks or support vector machines, to see if they provide better performance on your dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [2.52 0.   0.   0.   6.85]\n",
      "acc(r2_score) for train = 98.32\n",
      "acc(relative error) for train = 7.04\n",
      "acc(rmse) for train = 66.23\n",
      "acc(mae) for train = 29.16\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [15.25 19.12  0.85  6.76  0.  ]\n",
      "acc(r2_score) for test = 96.83\n",
      "acc(relative error) for test = 15.38\n",
      "acc(rmse) for test = 90.39\n",
      "acc(mae) for test = 58.96\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "#random_forest = GridSearchCV(estimator=RandomForestRegressor(), param_grid={'n_estimators': [100, 1000]}, cv=5)\n",
    "random_forest = RandomForestRegressor()\n",
    "random_forest.fit(train, target)\n",
    "acc_model(6,random_forest,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "print(random_forest.get_params())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'bootstrap': True,\n 'max_depth': 90,\n 'max_features': 7,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'n_estimators': 200}"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuning the parameters\n",
    "parameters = {'bootstrap': [True],\n",
    "              'max_depth': [ 70, 80, 90],\n",
    "              'max_features': [2,3,4,5,6,7],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 200, 300]}\n",
    "# GridSearch\n",
    "grid_search = GridSearchCV(estimator = random_forest, param_grid = parameters, cv = 5, n_jobs = -1, verbose = 2)\n",
    "grid_search = grid_search.fit(train, target)\n",
    "grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.8 XGBoost\n",
    "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples. Reference Wikipedia.\n",
    "\n",
    "Model Improvement:\n",
    "1. Feature Selection: By selecting only the relevant features, you can reduce the complexity of the model and prevent overfitting.\n",
    "\n",
    "2. Regularization Strength: By adjusting the regularization strength parameter (alpha), you can control the trade-off between fitting the training data well and avoiding overfitting.\n",
    "\n",
    "3. Scaling: Scaling the data can help to improve the performance of the model, especially when the features have vastly different ranges.\n",
    "\n",
    "4. Cross-Validation: Cross-validation can help to evaluate model performance and select the best hyperparameters.\n",
    "\n",
    "5. Grid Search: Grid search can be used to identify the optimal hyperparameters for the model by trying different combinations of hyperparameters.\n",
    "\n",
    "6. Ensemble Methods: You can use ensemble methods like bagging or boosting to improve the performance of the model by combining multiple models.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.863\n",
      "Best parameters set: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 140, 'reg_lambda': 0.5}\n",
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [ 2.038697    0.00718174  0.01788602 -0.01223567  6.882671  ]\n",
      "acc(r2_score) for train = 99.97\n",
      "acc(relative error) for train = 1.44\n",
      "acc(rmse) for train = 8.69\n",
      "acc(mae) for train = 5.96\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [ 1.4035552e+01  2.2608608e+01  9.0486073e-01  8.2483301e+00\n",
      " -2.8453700e-03]\n",
      "acc(r2_score) for test = 97.64\n",
      "acc(relative error) for test = 11.93\n",
      "acc(rmse) for test = 77.93\n",
      "acc(mae) for test = 45.74\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBRegressor(objective = 'reg:squarederror')\n",
    "parameters = {'n_estimators': [60, 100, 120, 140],\n",
    "              'learning_rate': [0.01, 0.1],\n",
    "              'max_depth': [5, 7],\n",
    "              'reg_lambda': [0.5]}\n",
    "xgb_reg = GridSearchCV(estimator=xgb_clf, param_grid=parameters, cv=5, n_jobs=-1).fit(trainb, targetb)\n",
    "print(\"Best score: %0.3f\" % xgb_reg.best_score_)\n",
    "print(\"Best parameters set:\", xgb_reg.best_params_)\n",
    "acc_boosting_model(7,xgb_reg,trainb,testb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.9 LightGBM\n",
    "LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages: Faster training speed and higher efficiency. Lower memory usage. Better accuracy. Support of parallel and GPU learning. Capable of handling large-scale data. Reference Wikipedia.\n",
    "\n",
    "Model Improvement:\n",
    "1. Tune hyperparameters: XGBoost has many hyperparameters that can affect model performance, such as the learning rate, number of trees, max depth, min child weight, and subsample rate. Experimenting with different combinations of hyperparameters can often lead to significant improvements in performance. You can use techniques like grid search or random search to find the optimal hyperparameters for your specific problem.\n",
    "\n",
    "2. Feature engineering: Creating new features or transforming existing features can improve the predictive power of your model. For example, you can try binning continuous variables, creating interaction terms, or encoding categorical variables.\n",
    "\n",
    "3. Increase the number of trees: The number of trees in an XGBoost model can greatly affect its performance. You can experiment with increasing the number of trees until you start to see diminishing returns in performance.\n",
    "\n",
    "4. Use early stopping: XGBoost allows for early stopping, which can help prevent overfitting and improve model performance. You can monitor the performance of your model on a validation set and stop training once the performance stops improving.\n",
    "\n",
    "5. Regularization: XGBoost offers several forms of regularization, such as L1 and L2 regularization, which can help prevent overfitting and improve model performance. You can experiment with different regularization parameters to find the optimal setting for your model.\n",
    "\n",
    "6. Ensemble learning: You can combine multiple XGBoost models into an ensemble to improve performance. Ensemble methods like bagging, boosting, and stacking can help reduce variance and improve model accuracy.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "Xtrain, Xval, Ztrain, Zval = train_test_split(trainb, targetb, test_size=0.2, random_state=0)\n",
    "train_set = lgb.Dataset(Xtrain, Ztrain, silent=False)\n",
    "valid_set = lgb.Dataset(Xval, Zval, silent=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=0.8 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=0.8 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 116\n",
      "[LightGBM] [Info] Number of data points in the train set: 153, number of used features: 7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=0.8 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Info] Start training from score 4.215686\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[500]\tvalid_0's rmse: 1.83175\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1000]\tvalid_0's rmse: 1.83175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[286]\tvalid_0's rmse: 1.82767\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {\n",
    "    'boosting_type':'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,\n",
    "    'subsample': 0.8,\n",
    "    'bagging_fraction' : 1,\n",
    "    'max_bin' : 5000 ,\n",
    "    'bagging_freq': 20,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'metric': 'rmse',\n",
    "    'min_split_gain': 0.5,\n",
    "    'min_child_weight': 1,\n",
    "    'min_child_samples': 10,\n",
    "    'scale_pos_weight':1,\n",
    "    'zero_as_missing': False,\n",
    "    'seed':0,\n",
    "    'lambda_l2': 0.1,\n",
    "}\n",
    "modelL = lgb.train(params, train_set = train_set, num_boost_round=1000,\n",
    "                   early_stopping_rounds=800,verbose_eval=500, valid_sets=valid_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [ 1.53290397  0.05197494 -0.05307475 -0.44752419  7.32934543]\n",
      "acc(r2_score) for train = 93.5\n",
      "acc(relative error) for train = 17.04\n",
      "acc(rmse) for train = 130.32\n",
      "acc(mae) for train = 70.55\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [16.77426511 21.00969488  0.45413043 13.27340528  1.18569097]\n",
      "acc(r2_score) for test = 91.67\n",
      "acc(relative error) for test = 28.96\n",
      "acc(rmse) for test = 146.53\n",
      "acc(mae) for test = 111.02\n"
     ]
    }
   ],
   "source": [
    "# Use function to evaluate model\n",
    "acc_boosting_model(8,modelL,trainb,testb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "{'colsample_bytree': 1,\n 'learning_rate': 0.1,\n 'max_depth': 7,\n 'min_child_samples': 10,\n 'min_child_weight': 1,\n 'min_split_gain': 0.5,\n 'n_estimators': 100,\n 'num_leaves': 31,\n 'reg_lambda': 0.1,\n 'subsample': 0.8}"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter Tuning\n",
    "parameters = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [5, 7],\n",
    "    'num_leaves': [31, 63],\n",
    "    'min_child_samples': [10, 20],\n",
    "    'min_child_weight': [1, 2],\n",
    "    'min_split_gain': [0.5, 1],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.6, 1],\n",
    "    'reg_lambda': [0.1, 1],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "lgbm = lgb.LGBMRegressor()\n",
    "grid_search = GridSearchCV(estimator=lgbm, param_grid=parameters, cv=5, n_jobs=-1).fit(trainb, targetb)\n",
    "grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.10 Gradient Boosting Regressor with HyperOpt\n",
    "Gradient Boosting builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage nclasses regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced. The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data and max_features=n_features, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed. Reference sklearn documentation.\n",
    "\n",
    "Model Improvement:\n",
    "1. Increasing the number of trees: Gradient boosting works by combining the predictions of multiple weak learners (i.e., trees). Adding more trees can improve the model's accuracy, but may also increase its complexity and lead to overfitting.\n",
    "\n",
    "2. Tuning the learning rate: The learning rate determines the contribution of each tree to the final prediction. A smaller learning rate results in a more robust model but requires more trees to achieve the same level of accuracy.\n",
    "\n",
    "3. Regularizing the model: Regularization techniques, such as L1/L2 regularization, can help prevent overfitting by penalizing large coefficients. Another option is early stopping, which stops training once the performance on a validation set starts to degrade.\n",
    "\n",
    "4. Addressing missing values: Gradient boosting algorithms cannot handle missing values, so it is important to either impute them or exclude them from the dataset.\n",
    "\n",
    "5. Feature engineering: Feature engineering involves creating new features or transforming existing ones to better capture the underlying patterns in the data. This can help improve model performance by providing more relevant information to the algorithm.\n",
    "\n",
    "6. Using a more advanced algorithm: Gradient boosting is just one of many regression algorithms available. It may be worth exploring other algorithms, such as neural networks or support vector machines, to see if they provide better performance on your dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8354951061318934                                    \n",
      "{'max_depth': 2, 'n_estimators': 439}                 \n",
      "0.8323609222143945                                                              \n",
      "{'max_depth': 6, 'n_estimators': 314}                                           \n",
      "0.8116292707075103                                                              \n",
      "{'max_depth': 8, 'n_estimators': 690}                                           \n",
      "0.8407208415503119                                                              \n",
      "{'max_depth': 2, 'n_estimators': 504}                                           \n",
      "0.8388431883735775                                                              \n",
      "{'max_depth': 2, 'n_estimators': 868}                                           \n",
      "0.8127082863895939                                                              \n",
      "{'max_depth': 9, 'n_estimators': 679}                                           \n",
      "0.8577011374451102                                                              \n",
      "{'max_depth': 3, 'n_estimators': 943}                                           \n",
      "0.8531399560055222                                                              \n",
      "{'max_depth': 3, 'n_estimators': 672}                                           \n",
      "0.8300795569780568                                                              \n",
      "{'max_depth': 6, 'n_estimators': 934}                                           \n",
      "0.8496113232914746                                                              \n",
      "{'max_depth': 4, 'n_estimators': 415}                                           \n",
      "100%|| 10/10 [00:18<00:00,  1.84s/trial, best loss: 0.8116292707075103]\n",
      "best:\n",
      "{'max_depth': 6, 'n_estimators': 590}\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_gb_score(params):\n",
    "    clf = GradientBoostingRegressor(**params)\n",
    "    current_score = cross_val_score(clf, train, target, cv=10).mean()\n",
    "    print(current_score, params)\n",
    "    return current_score\n",
    "\n",
    "space_gb = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(2, 10, dtype=int))\n",
    "}\n",
    "\n",
    "best = fmin(fn=hyperopt_gb_score, space=space_gb, algo=tpe.suggest, max_evals=10)\n",
    "print('best:')\n",
    "print(best)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_depth': 8, 'n_estimators': 690}"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = space_eval(space_gb, best)\n",
    "params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [ 2.00000000e+00 -3.79195170e-10  6.04709765e-09  1.98372188e-08\n",
      "  6.99999997e+00]\n",
      "acc(r2_score) for train = 100.0\n",
      "acc(relative error) for train = 0.0\n",
      "acc(rmse) for train = 0.0\n",
      "acc(mae) for train = 0.0\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [ 1.40000000e+01  2.29999190e+01  1.00001947e+00  7.96416511e+00\n",
      " -1.11907730e-07]\n",
      "acc(r2_score) for test = 95.92\n",
      "acc(relative error) for test = 15.33\n",
      "acc(rmse) for test = 102.48\n",
      "acc(mae) for test = 58.76\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regression\n",
    "\n",
    "gradient_boosting = GradientBoostingRegressor(**params)\n",
    "gradient_boosting.fit(train, target)\n",
    "acc_model(9,gradient_boosting,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.11 Ridge Regressor\n",
    "Tikhonov Regularization, colloquially known as Ridge Regression, is the most commonly used regression algorithm to approximate an answer for an equation with no unique solution. This type of problem is very common in machine learning tasks, where the \"best\" solution must be chosen using limited data. If a unique solution exists, algorithm will return the optimal value. However, if multiple solutions exist, it may choose any of them. Reference Brilliant.org.\n",
    "\n",
    "Model Improvement:\n",
    "1. Feature Selection: By selecting only the relevant features, you can reduce the complexity of the model and prevent overfitting.\n",
    "\n",
    "2. Regularization Strength: By adjusting the regularization strength parameter (alpha), you can control the trade-off between fitting the training data well and avoiding overfitting.\n",
    "\n",
    "3. Scaling: Scaling the data can help to improve the performance of the model, especially when the features have vastly different ranges.\n",
    "\n",
    "4. Cross-Validation: Cross-validation can help to evaluate model performance and select the best hyperparameters.\n",
    "\n",
    "5. Grid Search: Grid search can be used to identify the optimal hyperparameters for the model by trying different combinations of hyperparameters.\n",
    "\n",
    "6. Ensemble Methods: You can use ensemble methods like bagging or boosting to improve the performance of the model by combining multiple models.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [2.80302314 0.42630154 0.79777369 0.973802   6.57824184]\n",
      "acc(r2_score) for train = 86.34\n",
      "acc(relative error) for train = 30.68\n",
      "acc(rmse) for train = 188.83\n",
      "acc(mae) for train = 127.02\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [16.19815843 16.05746353  1.96791578  9.49766861  3.76771824]\n",
      "acc(r2_score) for test = 81.88\n",
      "acc(relative error) for test = 43.05\n",
      "acc(rmse) for test = 216.04\n",
      "acc(mae) for test = 165.03\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regressor\n",
    "\n",
    "ridge = RidgeCV(cv=5)\n",
    "ridge.fit(train, target)\n",
    "acc_model(10,ridge,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "{'alpha_per_target': 1, 'fit_intercept': True}"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "parameters = {'alpha_per_target': [0.1, 1, 10, 100],\n",
    "                'fit_intercept': [True,False]\n",
    "              }\n",
    "ridge = RidgeCV()\n",
    "clf = GridSearchCV(ridge, parameters)\n",
    "clf.fit(train, target)\n",
    "clf.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.12 Bagging Regressor\n",
    "Bootstrap aggregating, also called Bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach. Bagging leads to \"improvements for unstable procedures\", which include, for example, artificial neural networks, classification and regression trees, and subset selection in linear regression. On the other hand, it can mildly degrade the performance of stable methods such as K-nearest neighbors. Reference Wikipedia.\n",
    "\n",
    "Model Improvement:\n",
    "1. Increase the number of estimators: The bagging regressor averages the predictions from multiple base estimators. Hence, increasing the number of estimators can help in capturing a wider range of variability in the data and improve overall performance.\n",
    "\n",
    "2. Increase the sample size: Increasing the sample size can help in improving the diversity of samples used for building base models, thereby improving the bagging regressor's performance.\n",
    "\n",
    "3. Tuning Hyperparameters: Hyperparameters such as the maximum number of features and the minimum number of samples split may be tuned to optimize the model's performance.\n",
    "\n",
    "4. Feature Selection: Feature selection techniques can be employed to remove irrelevant or redundant features, which can lead to improved performance.\n",
    "\n",
    "5. Resampling: Resampling techniques such as oversampling or undersampling can be used to balance the distribution of the target variable, which can help improve the model's performance.\n",
    "\n",
    "6. Using a different base estimator: Switching to a different base estimator, such as support vector machines (SVMs) or random forests, may yield better performance in certain datasets.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [2.7 0.  0.  0.  6.9]\n",
      "acc(r2_score) for train = 97.02\n",
      "acc(relative error) for train = 8.44\n",
      "acc(rmse) for train = 88.2\n",
      "acc(mae) for train = 34.95\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [14.8 16.9  1.   7.   0. ]\n",
      "acc(r2_score) for test = 95.53\n",
      "acc(relative error) for test = 17.5\n",
      "acc(rmse) for test = 107.28\n",
      "acc(mae) for test = 67.08\n"
     ]
    }
   ],
   "source": [
    "# Bagging Regressor\n",
    "\n",
    "bagging = BaggingRegressor()\n",
    "bagging.fit(train, target)\n",
    "acc_model(11,bagging,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: -338.74 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'max_features': 1.0, 'max_samples': 0.9, 'n_estimators': 10}"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'n_estimators': [10, 50, 100, 200],\n",
    "              'max_samples': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "              'max_features': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]}\n",
    "grid_search = GridSearchCV(estimator = bagging,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'neg_mean_squared_error',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(train, target)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "best_parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.13 Extra Trees Regressor\n",
    "ExtraTreesRegressor implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values. Reference sklearn documentation.\n",
    "\n",
    "In extremely randomized trees, randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias. Reference sklearn documentation.\n",
    "\n",
    "Model Improvement:\n",
    "1. Hyperparameter Tuning: The performance of the Extra Trees Regressor can be significantly improved by tuning its hyperparameters. Some of the important hyperparameters to tune are the number of trees in the forest (n_estimators), the maximum depth of each tree (max_depth), the minimum number of samples required to split an internal node (min_samples_split), the minimum number of samples required to be at a leaf node (min_samples_leaf), among others. You can use techniques such as Grid Search or Random Search to find the best combination of hyperparameters.\n",
    "\n",
    "2. Feature Selection: You can try to improve the performance of the Extra Trees Regressor by selecting only the most important features. This can be achieved by using techniques such as Recursive Feature Elimination (RFE) or Feature Importance Ranking.\n",
    "\n",
    "3. Ensemble Learning: You can also improve the performance of the Extra Trees Regressor by combining it with other regression models such as Random Forests, Gradient Boosting, or AdaBoost. This can be achieved using techniques such as Stacking or Boosting.\n",
    "\n",
    "4. Data Preprocessing: Data preprocessing techniques such as normalization, standardization, or scaling can also help improve the performance of the Extra Trees Regressor.\n",
    "\n",
    "5. Cross-validation: It is important to evaluate the performance of the Extra Trees Regressor using cross-validation techniques such as k-fold cross-validation to ensure that the model is not overfitting or underfitting the data.\n",
    "\n",
    "6. Increasing the Size of the Dataset: Increasing the size of the dataset used for training can also help improve the performance of the Extra Trees Regressor by reducing the effect of noise and outliers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [2. 0. 0. 0. 7.]\n",
      "acc(r2_score) for train = 100.0\n",
      "acc(relative error) for train = 0.0\n",
      "acc(rmse) for train = 0.0\n",
      "acc(mae) for train = 0.0\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [14.14 22.91  0.93  9.11  0.  ]\n",
      "acc(r2_score) for test = 96.78\n",
      "acc(relative error) for test = 13.07\n",
      "acc(rmse) for test = 91.04\n",
      "acc(mae) for test = 50.1\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Regressor\n",
    "\n",
    "etr = ExtraTreesRegressor()\n",
    "etr.fit(train, target)\n",
    "acc_model(12,etr,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 7, 'min_samples_leaf': 5, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# GridSearch with Extra Trees Regressor\n",
    "etr = ExtraTreesRegressor()\n",
    "param_grid = {'n_estimators': [100, 200, 500],\n",
    "              'min_samples_leaf': [5, 10, 20, 40],\n",
    "              'max_features': [2,3,4,5,6,7]}\n",
    "grid_search = GridSearchCV(etr, param_grid, cv=5)\n",
    "grid_search.fit(train, target)\n",
    "print(grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.14 AdaBoost Regressor\n",
    "The core principle of AdaBoost is to fit a sequence of weak learners (i.e., models that are only slightly better than random guessing, such as small decision trees) on repeatedly modified versions of the data. The predictions from all of them are then combined through a weighted majority vote (or sum) to produce the final prediction. The data modifications at each so-called boosting iteration consist of applying N weights to each of the training samples. Initially, those weights are all set to 1/N, so that the first step simply trains a weak learner on the original data. For each successive iteration, the sample weights are individually modified and the learning algorithm is reapplied to the reweighted data. At a given step, those training examples that were incorrectly predicted by the boosted model induced at the previous step have their weights increased, whereas the weights are decreased for those that were predicted correctly. As iterations proceed, examples that are difficult to predict receive ever-increasing influence. Each subsequent weak learner is thereby forced to concentrate on the examples that are missed by the previous ones in the sequence. Reference sklearn documentation.\n",
    "\n",
    "Model Improvement:\n",
    "1. Adjusting the learning rate- the learning rate determines how much the contribution of each classifier affects the final outcome. If the learning rate is too high, the model may become very complex and overfit the data. If it's too low, the model may fail to capture the underlying patterns in the data. tuning the learning rate can improve the overall performance.\n",
    "\n",
    "2. Increasing the number of estimators- the more estimators there are, the more opportunities the model has to learn the underlying patterns in the data. Increasing the number of estimators can improve the overall performance of the model.\n",
    "\n",
    "3. Removing outliers- Ada Boost Regressor is sensitive to outliers because it is fitted using a weighted version of the data. Removing outliers from the dataset can improve the performance of the model.\n",
    "\n",
    "4. Feature selection- the model may be overfitting the data because it's using too many features. Removing irrelevant features can improve the performance of the model.\n",
    "\n",
    "5. Cross-validation- using cross-validation to evaluate the performance of the model can help identify the optimal hyperparameters, such as the learning rate and number of estimators. Cross-validation can provide insight into how well the model will perform on new data.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [3.88       0.44444444 0.44444444 0.44444444 7.6       ]\n",
      "acc(r2_score) for train = 96.64\n",
      "acc(relative error) for train = 17.67\n",
      "acc(rmse) for train = 93.61\n",
      "acc(mae) for train = 73.17\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [15.33333333 23.          0.64        7.625       0.44444444]\n",
      "acc(r2_score) for test = 94.03\n",
      "acc(relative error) for test = 25.3\n",
      "acc(rmse) for test = 124.04\n",
      "acc(mae) for test = 96.98\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Regression\n",
    "\n",
    "Ada_Boost = AdaBoostRegressor()\n",
    "Ada_Boost.fit(train, target)\n",
    "acc_model(13,Ada_Boost,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.15 Voting Regressor\n",
    "VotingRegressor is an ensemble meta-estimator that fits base regressors each on the whole dataset. It, then, averages the individual predictions to form a final prediction. Such a meta-estimator can be useful for a set of equally well performing model in order to balance out their individual weaknesses. Reference sklearn documentation.\n",
    "\n",
    "Model Improvement:\n",
    "1. Use a combination of diverse algorithms: A Voting Regressor combines the predictions of multiple base algorithms. Using a diverse set of algorithms with different strengths and weaknesses can improve the overall performance.\n",
    "\n",
    "2. Hyperparameter Tuning: Fine-tuning the hyperparameters of the base algorithms and the Voting Regressor itself can boost the performance. You can use techniques like Grid Search or Random Search for hyperparameter tuning.\n",
    "\n",
    "3. Feature Engineering: Building new features or selecting relevant features from the available dataset can improve the performance of the Voting Regressor.\n",
    "\n",
    "4. Outlier Detection: Outliers can have a significant impact on the performance of the model. Removing or treating outliers can improve the performance of the Voting Regressor.\n",
    "\n",
    "5. Ensemble Learning with Bagging or Boosting: Using Ensemble Learning techniques like Bagging or Boosting along with Voting Regressors can also improve the performance.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [2.69792504 0.46518294 0.8222522  0.9302291  6.56720124]\n",
      "acc(r2_score) for train = 86.51\n",
      "acc(relative error) for train = 30.57\n",
      "acc(rmse) for train = 187.7\n",
      "acc(mae) for train = 126.58\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [16.45926634 16.28914939  2.07721834  9.58136894  3.78603899]\n",
      "acc(r2_score) for test = 82.02\n",
      "acc(relative error) for test = 42.98\n",
      "acc(rmse) for test = 215.24\n",
      "acc(mae) for test = 164.78\n"
     ]
    }
   ],
   "source": [
    "Voting_Reg = VotingRegressor(estimators=[('lin', linreg), ('ridge', ridge), ('sgd', sgd)])\n",
    "Voting_Reg.fit(train, target)\n",
    "acc_model(14,Voting_Reg,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': [0.3, 0.4, 0.3]}\n"
     ]
    }
   ],
   "source": [
    "# Parameter Tuning\n",
    "params = {'weights': [[0.1, 0.2, 0.7], [0.2, 0.3, 0.5], [0.3, 0.4, 0.3], [0.4, 0.3, 0.3], [0.5, 0.2, 0.3], [0.6, 0.2, 0.2], [0.7, 0.1, 0.2], [0.8, 0.1, 0.1], [0.9, 0.05, 0.05]]}\n",
    "grid = GridSearchCV(Voting_Reg, param_grid=params, cv=5, scoring='r2')\n",
    "grid.fit(train, target)\n",
    "print(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =  [2 0 0 0 7]\n",
      "ytrain =  [2.7070612  0.46078849 0.82092719 0.9389384  6.56603074]\n",
      "acc(r2_score) for train = 86.5\n",
      "acc(relative error) for train = 30.58\n",
      "acc(rmse) for train = 187.77\n",
      "acc(mae) for train = 126.62\n",
      "target_test = [14 20  1  9  0]\n",
      "ytest = [16.42306567 16.25932207  2.06717397  9.56819602  3.78169031]\n",
      "acc(r2_score) for test = 82.03\n",
      "acc(relative error) for test = 42.97\n",
      "acc(rmse) for test = 215.17\n",
      "acc(mae) for test = 164.7\n"
     ]
    }
   ],
   "source": [
    "Voting_Reg = VotingRegressor(estimators=[('lin', linreg), ('ridge', ridge), ('sgd', sgd)], weights=[0.3, 0.4, 0.3])\n",
    "Voting_Reg.fit(train, target)\n",
    "acc_model(14,Voting_Reg,train,test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Modell Comparison\n",
    "To compare all models we derive the metrics for all models and compare them.\n",
    "\n",
    "*R2 Score*\n",
    "The R-squared test, also known as the coefficient of determination, is a statistical measure used to evaluate the goodness of fit of a regression model. It measures the proportion of the variation in the dependent variable that is explained by the independent variable(s).\n",
    "\n",
    "The R-squared value ranges from 0 to 1, where 0 indicates that the model does not fit the data and 1 indicates that the model perfectly fits the data. Typically, a higher R-squared value indicates a better fit of the model to the data.\n",
    "\n",
    "However, it is important to note that a high R-squared value does not necessarily mean that the model is accurate or that it can predict future values. Additionally, a low R-squared value does not necessarily mean that the model is not useful or accurate.\n",
    "\n",
    "Therefore, it is important to use additional methods such as residual plots, significance tests, and cross-validation to evaluate the performance of the regression model.\n",
    "\n",
    "\n",
    "*Durbin Watson Test:*\n",
    "The d-test or the Durbin-Watson test is used to check for the presence of autocorrelation in a regression model. Autocorrelation occurs when the residuals of a regression model are correlated, meaning that the errors of one observation are similar to the errors of its neighboring observations. This can cause problems with the statistical inference of the regression model, leading to biased estimates of the regression coefficients and incorrect standard errors.\n",
    "\n",
    "The d-test computes a test statistic that measures the degree of autocorrelation present in the residuals of a regression model. The test statistic, d, ranges from 0 to 4, with d = 2 indicating no autocorrelation, d < 2 indicating positive autocorrelation, and d > 2 indicating negative autocorrelation.\n",
    "\n",
    "To interpret the d-test, you can use the following general guidelines:\n",
    "\n",
    "- If d is close to 2, then the regression model does not exhibit significant autocorrelation.\n",
    "- If d is less than 2, then the regression model exhibits positive autocorrelation, meaning that the residuals of the model are positively correlated.\n",
    "- If d is greater than 2, then the regression model exhibits negative autocorrelation, meaning that the residuals of the model are negatively correlated.\n",
    "\n",
    "Typically, a d-test value between 1.5 and 2.5 suggests that the model is reasonably free from autocorrelation. However, the exact threshold for a significant d value can vary depending on the context of the analysis and other factors such as sample size and data structure. Therefore, it is important to use the d-test in conjunction with other diagnostic tests and visualizations to assess the validity of a regression model.\n",
    "\n",
    "*RMSE*\n",
    "The RMSE test (root mean squared error) evaluates the accuracy of a regression model by measuring the difference between the predicted values and the actual values. It is calculated by taking the square root of the average squared difference between the predicted and actual values.\n",
    "\n",
    "A lower RMSE value indicates that the model has better accuracy in predicting the outcome variable. However, the interpretation of the RMSE value depends on the scale of the outcome variable. For instance, an RMSE of 10 for a variable that ranges from 0 to 100 is different from an RMSE of 10 for a variable that ranges from 0 to 10. Therefore, it is essential to consider the context of the problem and the scale of the outcome variable when interpreting the RMSE value.\n",
    "\n",
    "*MAE*\n",
    "The MAE (Mean Absolute Error) test is a measure of the average absolute differences between the actual values and the predicted values made by a regression model. It is calculated by taking the sum of the absolute differences between actual and predicted values, and dividing this by the number of observations.\n",
    "\n",
    "Interpreting the MAE test result involves looking at the scale of the data being analyzed. The closer the MAE score is to zero, the smaller the error and the better the model's predictive power. A larger MAE score, on the other hand, indicates a larger difference between the actual and predicted values, suggesting that the model is less accurate. Therefore, a low MAE score is desirable, while a high MAE score indicates that the model is not accurate and may require further improvements.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Linear Regression',\n",
    "              'Support Vector Machines',\n",
    "              'Linear SVR',\n",
    "              'MLPRegressor',\n",
    "              'Stochastic Gradient Decent',\n",
    "              'Decision Tree Regressor',\n",
    "              'Random Forest',\n",
    "              'GradientBoostingRegressor',\n",
    "              'RidgeRegressor',\n",
    "              'XGBoost',\n",
    "              'LightGBM',\n",
    "              'BaggingRegressor',\n",
    "              'ExtraTreesRegressor',\n",
    "              'AdaBoostRegressor',\n",
    "              'VotingRegressor'],\n",
    "\n",
    "    'r2_train': acc_train_r2,\n",
    "    'r2_test': acc_test_r2,\n",
    "    'd_train': acc_train_d,\n",
    "    'd_test': acc_test_d,\n",
    "    'rmse_train': acc_train_rmse,\n",
    "    'rmse_test': acc_test_rmse,\n",
    "    'mae_train': acc_train_mae,\n",
    "    'mae_test': acc_test_mae\n",
    "})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "['Linear Regression',\n 'Support Vector Machines',\n 'Linear SVR',\n 'MLPRegressor',\n 'Stochastic Gradient Decent',\n 'Decision Tree Regressor',\n 'Random Forest',\n 'GradientBoostingRegressor',\n 'RidgeRegressor',\n 'XGBoost',\n 'LightGBM',\n 'BaggingRegressor',\n 'ExtraTreesRegressor',\n 'AdaBoostRegressor',\n 'VotingRegressor']"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.Model.to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy for models by R2 criterion - r2_test\n"
     ]
    },
    {
     "data": {
      "text/plain": "                         Model  r2_train  r2_test  d_train  d_test  \\\n11            BaggingRegressor     97.71    97.97     6.88   11.68   \n7    GradientBoostingRegressor     99.97    97.64     1.44   11.93   \n6                Random Forest     97.88    96.66     7.47   15.58   \n12         ExtraTreesRegressor    100.00    96.62     0.00   13.77   \n9                      XGBoost    100.00    95.19     0.00   16.50   \n13           AdaBoostRegressor     95.99    92.30    20.35   30.02   \n8               RidgeRegressor     93.50    91.67    17.04   28.96   \n3                 MLPRegressor     90.55    88.02    25.88   31.12   \n2                   Linear SVR     83.76    84.15    27.75   36.12   \n0            Linear Regression     86.53    82.07    30.50   42.93   \n14             VotingRegressor     86.50    82.02    30.58   42.97   \n4   Stochastic Gradient Decent     86.53    81.97    30.59   43.00   \n10                    LightGBM     86.34    81.88    30.68   43.05   \n5      Decision Tree Regressor     70.64    64.29    30.90   42.79   \n1      Support Vector Machines     48.61    63.97    31.39   36.20   \n\n    rmse_train  rmse_test  mae_train  mae_test  \n11       77.29      72.33      28.49     44.79  \n7         8.69      77.93       5.96     45.74  \n6        74.38      92.79      30.94     59.71  \n12        0.00      93.27       0.00     52.77  \n9         0.00     111.35       0.00     63.24  \n13      102.38     140.84      84.28    115.09  \n8       130.32     146.53      70.55    111.02  \n3       157.11     175.70     107.14    119.30  \n2       205.90     202.06     114.90    138.46  \n0       187.52     214.93     126.29    164.57  \n14      187.72     215.22     126.63    164.71  \n4       187.57     215.53     126.67    164.83  \n10      188.83     216.04     127.02    165.03  \n5       276.88     303.32     127.94    164.03  \n1       366.30     304.66     129.99    138.75  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>r2_train</th>\n      <th>r2_test</th>\n      <th>d_train</th>\n      <th>d_test</th>\n      <th>rmse_train</th>\n      <th>rmse_test</th>\n      <th>mae_train</th>\n      <th>mae_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>BaggingRegressor</td>\n      <td>97.71</td>\n      <td>97.97</td>\n      <td>6.88</td>\n      <td>11.68</td>\n      <td>77.29</td>\n      <td>72.33</td>\n      <td>28.49</td>\n      <td>44.79</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>GradientBoostingRegressor</td>\n      <td>99.97</td>\n      <td>97.64</td>\n      <td>1.44</td>\n      <td>11.93</td>\n      <td>8.69</td>\n      <td>77.93</td>\n      <td>5.96</td>\n      <td>45.74</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Random Forest</td>\n      <td>97.88</td>\n      <td>96.66</td>\n      <td>7.47</td>\n      <td>15.58</td>\n      <td>74.38</td>\n      <td>92.79</td>\n      <td>30.94</td>\n      <td>59.71</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ExtraTreesRegressor</td>\n      <td>100.00</td>\n      <td>96.62</td>\n      <td>0.00</td>\n      <td>13.77</td>\n      <td>0.00</td>\n      <td>93.27</td>\n      <td>0.00</td>\n      <td>52.77</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>XGBoost</td>\n      <td>100.00</td>\n      <td>95.19</td>\n      <td>0.00</td>\n      <td>16.50</td>\n      <td>0.00</td>\n      <td>111.35</td>\n      <td>0.00</td>\n      <td>63.24</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AdaBoostRegressor</td>\n      <td>95.99</td>\n      <td>92.30</td>\n      <td>20.35</td>\n      <td>30.02</td>\n      <td>102.38</td>\n      <td>140.84</td>\n      <td>84.28</td>\n      <td>115.09</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RidgeRegressor</td>\n      <td>93.50</td>\n      <td>91.67</td>\n      <td>17.04</td>\n      <td>28.96</td>\n      <td>130.32</td>\n      <td>146.53</td>\n      <td>70.55</td>\n      <td>111.02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MLPRegressor</td>\n      <td>90.55</td>\n      <td>88.02</td>\n      <td>25.88</td>\n      <td>31.12</td>\n      <td>157.11</td>\n      <td>175.70</td>\n      <td>107.14</td>\n      <td>119.30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Linear SVR</td>\n      <td>83.76</td>\n      <td>84.15</td>\n      <td>27.75</td>\n      <td>36.12</td>\n      <td>205.90</td>\n      <td>202.06</td>\n      <td>114.90</td>\n      <td>138.46</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression</td>\n      <td>86.53</td>\n      <td>82.07</td>\n      <td>30.50</td>\n      <td>42.93</td>\n      <td>187.52</td>\n      <td>214.93</td>\n      <td>126.29</td>\n      <td>164.57</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>VotingRegressor</td>\n      <td>86.50</td>\n      <td>82.02</td>\n      <td>30.58</td>\n      <td>42.97</td>\n      <td>187.72</td>\n      <td>215.22</td>\n      <td>126.63</td>\n      <td>164.71</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Stochastic Gradient Decent</td>\n      <td>86.53</td>\n      <td>81.97</td>\n      <td>30.59</td>\n      <td>43.00</td>\n      <td>187.57</td>\n      <td>215.53</td>\n      <td>126.67</td>\n      <td>164.83</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBM</td>\n      <td>86.34</td>\n      <td>81.88</td>\n      <td>30.68</td>\n      <td>43.05</td>\n      <td>188.83</td>\n      <td>216.04</td>\n      <td>127.02</td>\n      <td>165.03</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Decision Tree Regressor</td>\n      <td>70.64</td>\n      <td>64.29</td>\n      <td>30.90</td>\n      <td>42.79</td>\n      <td>276.88</td>\n      <td>303.32</td>\n      <td>127.94</td>\n      <td>164.03</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Support Vector Machines</td>\n      <td>48.61</td>\n      <td>63.97</td>\n      <td>31.39</td>\n      <td>36.20</td>\n      <td>366.30</td>\n      <td>304.66</td>\n      <td>129.99</td>\n      <td>138.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Prediction accuracy for models by R2 criterion - r2_test')\n",
    "models.sort_values(by=['r2_test', 'r2_train'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy for models by relative error - d_test\n"
     ]
    },
    {
     "data": {
      "text/plain": "                         Model  r2_train  r2_test  d_train  d_test  \\\n11            BaggingRegressor     97.71    97.97     6.88   11.68   \n7    GradientBoostingRegressor     99.97    97.64     1.44   11.93   \n12         ExtraTreesRegressor    100.00    96.62     0.00   13.77   \n6                Random Forest     97.88    96.66     7.47   15.58   \n9                      XGBoost    100.00    95.19     0.00   16.50   \n8               RidgeRegressor     93.50    91.67    17.04   28.96   \n13           AdaBoostRegressor     95.99    92.30    20.35   30.02   \n3                 MLPRegressor     90.55    88.02    25.88   31.12   \n2                   Linear SVR     83.76    84.15    27.75   36.12   \n1      Support Vector Machines     48.61    63.97    31.39   36.20   \n5      Decision Tree Regressor     70.64    64.29    30.90   42.79   \n0            Linear Regression     86.53    82.07    30.50   42.93   \n14             VotingRegressor     86.50    82.02    30.58   42.97   \n4   Stochastic Gradient Decent     86.53    81.97    30.59   43.00   \n10                    LightGBM     86.34    81.88    30.68   43.05   \n\n    rmse_train  rmse_test  mae_train  mae_test  \n11       77.29      72.33      28.49     44.79  \n7         8.69      77.93       5.96     45.74  \n12        0.00      93.27       0.00     52.77  \n6        74.38      92.79      30.94     59.71  \n9         0.00     111.35       0.00     63.24  \n8       130.32     146.53      70.55    111.02  \n13      102.38     140.84      84.28    115.09  \n3       157.11     175.70     107.14    119.30  \n2       205.90     202.06     114.90    138.46  \n1       366.30     304.66     129.99    138.75  \n5       276.88     303.32     127.94    164.03  \n0       187.52     214.93     126.29    164.57  \n14      187.72     215.22     126.63    164.71  \n4       187.57     215.53     126.67    164.83  \n10      188.83     216.04     127.02    165.03  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>r2_train</th>\n      <th>r2_test</th>\n      <th>d_train</th>\n      <th>d_test</th>\n      <th>rmse_train</th>\n      <th>rmse_test</th>\n      <th>mae_train</th>\n      <th>mae_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>BaggingRegressor</td>\n      <td>97.71</td>\n      <td>97.97</td>\n      <td>6.88</td>\n      <td>11.68</td>\n      <td>77.29</td>\n      <td>72.33</td>\n      <td>28.49</td>\n      <td>44.79</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>GradientBoostingRegressor</td>\n      <td>99.97</td>\n      <td>97.64</td>\n      <td>1.44</td>\n      <td>11.93</td>\n      <td>8.69</td>\n      <td>77.93</td>\n      <td>5.96</td>\n      <td>45.74</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ExtraTreesRegressor</td>\n      <td>100.00</td>\n      <td>96.62</td>\n      <td>0.00</td>\n      <td>13.77</td>\n      <td>0.00</td>\n      <td>93.27</td>\n      <td>0.00</td>\n      <td>52.77</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Random Forest</td>\n      <td>97.88</td>\n      <td>96.66</td>\n      <td>7.47</td>\n      <td>15.58</td>\n      <td>74.38</td>\n      <td>92.79</td>\n      <td>30.94</td>\n      <td>59.71</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>XGBoost</td>\n      <td>100.00</td>\n      <td>95.19</td>\n      <td>0.00</td>\n      <td>16.50</td>\n      <td>0.00</td>\n      <td>111.35</td>\n      <td>0.00</td>\n      <td>63.24</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RidgeRegressor</td>\n      <td>93.50</td>\n      <td>91.67</td>\n      <td>17.04</td>\n      <td>28.96</td>\n      <td>130.32</td>\n      <td>146.53</td>\n      <td>70.55</td>\n      <td>111.02</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AdaBoostRegressor</td>\n      <td>95.99</td>\n      <td>92.30</td>\n      <td>20.35</td>\n      <td>30.02</td>\n      <td>102.38</td>\n      <td>140.84</td>\n      <td>84.28</td>\n      <td>115.09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MLPRegressor</td>\n      <td>90.55</td>\n      <td>88.02</td>\n      <td>25.88</td>\n      <td>31.12</td>\n      <td>157.11</td>\n      <td>175.70</td>\n      <td>107.14</td>\n      <td>119.30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Linear SVR</td>\n      <td>83.76</td>\n      <td>84.15</td>\n      <td>27.75</td>\n      <td>36.12</td>\n      <td>205.90</td>\n      <td>202.06</td>\n      <td>114.90</td>\n      <td>138.46</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Support Vector Machines</td>\n      <td>48.61</td>\n      <td>63.97</td>\n      <td>31.39</td>\n      <td>36.20</td>\n      <td>366.30</td>\n      <td>304.66</td>\n      <td>129.99</td>\n      <td>138.75</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Decision Tree Regressor</td>\n      <td>70.64</td>\n      <td>64.29</td>\n      <td>30.90</td>\n      <td>42.79</td>\n      <td>276.88</td>\n      <td>303.32</td>\n      <td>127.94</td>\n      <td>164.03</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression</td>\n      <td>86.53</td>\n      <td>82.07</td>\n      <td>30.50</td>\n      <td>42.93</td>\n      <td>187.52</td>\n      <td>214.93</td>\n      <td>126.29</td>\n      <td>164.57</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>VotingRegressor</td>\n      <td>86.50</td>\n      <td>82.02</td>\n      <td>30.58</td>\n      <td>42.97</td>\n      <td>187.72</td>\n      <td>215.22</td>\n      <td>126.63</td>\n      <td>164.71</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Stochastic Gradient Decent</td>\n      <td>86.53</td>\n      <td>81.97</td>\n      <td>30.59</td>\n      <td>43.00</td>\n      <td>187.57</td>\n      <td>215.53</td>\n      <td>126.67</td>\n      <td>164.83</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBM</td>\n      <td>86.34</td>\n      <td>81.88</td>\n      <td>30.68</td>\n      <td>43.05</td>\n      <td>188.83</td>\n      <td>216.04</td>\n      <td>127.02</td>\n      <td>165.03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Prediction accuracy for models by relative error - d_test')\n",
    "models.sort_values(by=['d_test', 'd_train'], ascending=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy for models by RMSE - rmse_test\n"
     ]
    },
    {
     "data": {
      "text/plain": "                         Model  r2_train  r2_test  d_train  d_test  \\\n11            BaggingRegressor     97.71    97.97     6.88   11.68   \n7    GradientBoostingRegressor     99.97    97.64     1.44   11.93   \n6                Random Forest     97.88    96.66     7.47   15.58   \n12         ExtraTreesRegressor    100.00    96.62     0.00   13.77   \n9                      XGBoost    100.00    95.19     0.00   16.50   \n13           AdaBoostRegressor     95.99    92.30    20.35   30.02   \n8               RidgeRegressor     93.50    91.67    17.04   28.96   \n3                 MLPRegressor     90.55    88.02    25.88   31.12   \n2                   Linear SVR     83.76    84.15    27.75   36.12   \n0            Linear Regression     86.53    82.07    30.50   42.93   \n14             VotingRegressor     86.50    82.02    30.58   42.97   \n4   Stochastic Gradient Decent     86.53    81.97    30.59   43.00   \n10                    LightGBM     86.34    81.88    30.68   43.05   \n5      Decision Tree Regressor     70.64    64.29    30.90   42.79   \n1      Support Vector Machines     48.61    63.97    31.39   36.20   \n\n    rmse_train  rmse_test  mae_train  mae_test  \n11       77.29      72.33      28.49     44.79  \n7         8.69      77.93       5.96     45.74  \n6        74.38      92.79      30.94     59.71  \n12        0.00      93.27       0.00     52.77  \n9         0.00     111.35       0.00     63.24  \n13      102.38     140.84      84.28    115.09  \n8       130.32     146.53      70.55    111.02  \n3       157.11     175.70     107.14    119.30  \n2       205.90     202.06     114.90    138.46  \n0       187.52     214.93     126.29    164.57  \n14      187.72     215.22     126.63    164.71  \n4       187.57     215.53     126.67    164.83  \n10      188.83     216.04     127.02    165.03  \n5       276.88     303.32     127.94    164.03  \n1       366.30     304.66     129.99    138.75  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>r2_train</th>\n      <th>r2_test</th>\n      <th>d_train</th>\n      <th>d_test</th>\n      <th>rmse_train</th>\n      <th>rmse_test</th>\n      <th>mae_train</th>\n      <th>mae_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>BaggingRegressor</td>\n      <td>97.71</td>\n      <td>97.97</td>\n      <td>6.88</td>\n      <td>11.68</td>\n      <td>77.29</td>\n      <td>72.33</td>\n      <td>28.49</td>\n      <td>44.79</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>GradientBoostingRegressor</td>\n      <td>99.97</td>\n      <td>97.64</td>\n      <td>1.44</td>\n      <td>11.93</td>\n      <td>8.69</td>\n      <td>77.93</td>\n      <td>5.96</td>\n      <td>45.74</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Random Forest</td>\n      <td>97.88</td>\n      <td>96.66</td>\n      <td>7.47</td>\n      <td>15.58</td>\n      <td>74.38</td>\n      <td>92.79</td>\n      <td>30.94</td>\n      <td>59.71</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ExtraTreesRegressor</td>\n      <td>100.00</td>\n      <td>96.62</td>\n      <td>0.00</td>\n      <td>13.77</td>\n      <td>0.00</td>\n      <td>93.27</td>\n      <td>0.00</td>\n      <td>52.77</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>XGBoost</td>\n      <td>100.00</td>\n      <td>95.19</td>\n      <td>0.00</td>\n      <td>16.50</td>\n      <td>0.00</td>\n      <td>111.35</td>\n      <td>0.00</td>\n      <td>63.24</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AdaBoostRegressor</td>\n      <td>95.99</td>\n      <td>92.30</td>\n      <td>20.35</td>\n      <td>30.02</td>\n      <td>102.38</td>\n      <td>140.84</td>\n      <td>84.28</td>\n      <td>115.09</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RidgeRegressor</td>\n      <td>93.50</td>\n      <td>91.67</td>\n      <td>17.04</td>\n      <td>28.96</td>\n      <td>130.32</td>\n      <td>146.53</td>\n      <td>70.55</td>\n      <td>111.02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MLPRegressor</td>\n      <td>90.55</td>\n      <td>88.02</td>\n      <td>25.88</td>\n      <td>31.12</td>\n      <td>157.11</td>\n      <td>175.70</td>\n      <td>107.14</td>\n      <td>119.30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Linear SVR</td>\n      <td>83.76</td>\n      <td>84.15</td>\n      <td>27.75</td>\n      <td>36.12</td>\n      <td>205.90</td>\n      <td>202.06</td>\n      <td>114.90</td>\n      <td>138.46</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression</td>\n      <td>86.53</td>\n      <td>82.07</td>\n      <td>30.50</td>\n      <td>42.93</td>\n      <td>187.52</td>\n      <td>214.93</td>\n      <td>126.29</td>\n      <td>164.57</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>VotingRegressor</td>\n      <td>86.50</td>\n      <td>82.02</td>\n      <td>30.58</td>\n      <td>42.97</td>\n      <td>187.72</td>\n      <td>215.22</td>\n      <td>126.63</td>\n      <td>164.71</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Stochastic Gradient Decent</td>\n      <td>86.53</td>\n      <td>81.97</td>\n      <td>30.59</td>\n      <td>43.00</td>\n      <td>187.57</td>\n      <td>215.53</td>\n      <td>126.67</td>\n      <td>164.83</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBM</td>\n      <td>86.34</td>\n      <td>81.88</td>\n      <td>30.68</td>\n      <td>43.05</td>\n      <td>188.83</td>\n      <td>216.04</td>\n      <td>127.02</td>\n      <td>165.03</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Decision Tree Regressor</td>\n      <td>70.64</td>\n      <td>64.29</td>\n      <td>30.90</td>\n      <td>42.79</td>\n      <td>276.88</td>\n      <td>303.32</td>\n      <td>127.94</td>\n      <td>164.03</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Support Vector Machines</td>\n      <td>48.61</td>\n      <td>63.97</td>\n      <td>31.39</td>\n      <td>36.20</td>\n      <td>366.30</td>\n      <td>304.66</td>\n      <td>129.99</td>\n      <td>138.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Prediction accuracy for models by RMSE - rmse_test')\n",
    "models.sort_values(by=['rmse_test', 'rmse_train'], ascending=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "r2_train",
         "x": [
          "Linear Regression",
          "Support Vector Machines",
          "Linear SVR",
          "MLPRegressor",
          "Stochastic Gradient Decent",
          "Decision Tree Regressor",
          "Random Forest",
          "GradientBoostingRegressor",
          "RidgeRegressor",
          "XGBoost",
          "LightGBM",
          "BaggingRegressor",
          "ExtraTreesRegressor",
          "AdaBoostRegressor",
          "VotingRegressor"
         ],
         "y": [
          86.53,
          48.61,
          83.76,
          90.55,
          86.53,
          70.64,
          97.88,
          99.97,
          93.5,
          100.0,
          86.34,
          97.71,
          100.0,
          95.99,
          86.5
         ],
         "type": "scatter"
        },
        {
         "name": "r2_test",
         "x": [
          "Linear Regression",
          "Support Vector Machines",
          "Linear SVR",
          "MLPRegressor",
          "Stochastic Gradient Decent",
          "Decision Tree Regressor",
          "Random Forest",
          "GradientBoostingRegressor",
          "RidgeRegressor",
          "XGBoost",
          "LightGBM",
          "BaggingRegressor",
          "ExtraTreesRegressor",
          "AdaBoostRegressor",
          "VotingRegressor"
         ],
         "y": [
          82.07,
          63.97,
          84.15,
          88.02,
          81.97,
          64.29,
          96.66,
          97.64,
          91.67,
          95.19,
          81.88,
          97.97,
          96.62,
          92.3,
          82.02
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "bgcolor": "rgb(17,17,17)",
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "rgb(17,17,17)",
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "subunitcolor": "#506784",
           "showland": true,
           "showlakes": true,
           "lakecolor": "rgb(17,17,17)"
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "borderwidth": 1,
           "bordercolor": "rgb(17,17,17)",
           "tickwidth": 0
          },
          "mapbox": {
           "style": "dark"
          }
         }
        },
        "title": {
         "text": "R2-criterion for 15 popular models for train and test datasets"
        },
        "xaxis": {
         "title": {
          "text": "Models"
         }
        },
        "yaxis": {
         "title": {
          "text": "R2-criterion, %"
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"3cf22117-305c-408d-ae3f-8c0282922364\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3cf22117-305c-408d-ae3f-8c0282922364\")) {                    Plotly.newPlot(                        \"3cf22117-305c-408d-ae3f-8c0282922364\",                        [{\"name\":\"r2_train\",\"x\":[\"Linear Regression\",\"Support Vector Machines\",\"Linear SVR\",\"MLPRegressor\",\"Stochastic Gradient Decent\",\"Decision Tree Regressor\",\"Random Forest\",\"GradientBoostingRegressor\",\"RidgeRegressor\",\"XGBoost\",\"LightGBM\",\"BaggingRegressor\",\"ExtraTreesRegressor\",\"AdaBoostRegressor\",\"VotingRegressor\"],\"y\":[86.53,48.61,83.76,90.55,86.53,70.64,97.88,99.97,93.5,100.0,86.34,97.71,100.0,95.99,86.5],\"type\":\"scatter\"},{\"name\":\"r2_test\",\"x\":[\"Linear Regression\",\"Support Vector Machines\",\"Linear SVR\",\"MLPRegressor\",\"Stochastic Gradient Decent\",\"Decision Tree Regressor\",\"Random Forest\",\"GradientBoostingRegressor\",\"RidgeRegressor\",\"XGBoost\",\"LightGBM\",\"BaggingRegressor\",\"ExtraTreesRegressor\",\"AdaBoostRegressor\",\"VotingRegressor\"],\"y\":[82.07,63.97,84.15,88.02,81.97,64.29,96.66,97.64,91.67,95.19,81.88,97.97,96.62,92.3,82.02],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"title\":{\"text\":\"R2-criterion for 15 popular models for train and test datasets\"},\"xaxis\":{\"title\":{\"text\":\"Models\"}},\"yaxis\":{\"title\":{\"text\":\"R2-criterion, %\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('3cf22117-305c-408d-ae3f-8c0282922364');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot with plotly dark theme\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=models['Model'], y=models['r2_train'], name='r2_train'))\n",
    "fig.add_trace(go.Scatter(x=models['Model'], y=models['r2_test'], name='r2_test'))\n",
    "fig.update_layout(title='R2-criterion for 15 popular models for train and test datasets',\n",
    "                   xaxis_title='Models',\n",
    "                   yaxis_title='R2-criterion, %')\n",
    "fig.update_layout(template='plotly_dark')\n",
    "# update size\n",
    "fig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "d_train",
         "x": [
          "Linear Regression",
          "Support Vector Machines",
          "Linear SVR",
          "MLPRegressor",
          "Stochastic Gradient Decent",
          "Decision Tree Regressor",
          "Random Forest",
          "GradientBoostingRegressor",
          "RidgeRegressor",
          "XGBoost",
          "LightGBM",
          "BaggingRegressor",
          "ExtraTreesRegressor",
          "AdaBoostRegressor",
          "VotingRegressor"
         ],
         "y": [
          30.5,
          31.39,
          27.75,
          25.88,
          30.59,
          30.9,
          7.47,
          1.44,
          17.04,
          0.0,
          30.68,
          6.88,
          0.0,
          20.35,
          30.58
         ],
         "type": "scatter"
        },
        {
         "name": "d_test",
         "x": [
          "Linear Regression",
          "Support Vector Machines",
          "Linear SVR",
          "MLPRegressor",
          "Stochastic Gradient Decent",
          "Decision Tree Regressor",
          "Random Forest",
          "GradientBoostingRegressor",
          "RidgeRegressor",
          "XGBoost",
          "LightGBM",
          "BaggingRegressor",
          "ExtraTreesRegressor",
          "AdaBoostRegressor",
          "VotingRegressor"
         ],
         "y": [
          42.93,
          36.2,
          36.12,
          31.12,
          43.0,
          42.79,
          15.58,
          11.93,
          28.96,
          16.5,
          43.05,
          11.68,
          13.77,
          30.02,
          42.97
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "bgcolor": "rgb(17,17,17)",
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "rgb(17,17,17)",
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "subunitcolor": "#506784",
           "showland": true,
           "showlakes": true,
           "lakecolor": "rgb(17,17,17)"
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "borderwidth": 1,
           "bordercolor": "rgb(17,17,17)",
           "tickwidth": 0
          },
          "mapbox": {
           "style": "dark"
          }
         }
        },
        "title": {
         "text": "Relative errors for 15 popular models for train and test datasets"
        },
        "xaxis": {
         "title": {
          "text": "Models"
         }
        },
        "yaxis": {
         "title": {
          "text": "Relative error, %"
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"ff075f75-921d-4fee-b923-0aef081c6f58\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ff075f75-921d-4fee-b923-0aef081c6f58\")) {                    Plotly.newPlot(                        \"ff075f75-921d-4fee-b923-0aef081c6f58\",                        [{\"name\":\"d_train\",\"x\":[\"Linear Regression\",\"Support Vector Machines\",\"Linear SVR\",\"MLPRegressor\",\"Stochastic Gradient Decent\",\"Decision Tree Regressor\",\"Random Forest\",\"GradientBoostingRegressor\",\"RidgeRegressor\",\"XGBoost\",\"LightGBM\",\"BaggingRegressor\",\"ExtraTreesRegressor\",\"AdaBoostRegressor\",\"VotingRegressor\"],\"y\":[30.5,31.39,27.75,25.88,30.59,30.9,7.47,1.44,17.04,0.0,30.68,6.88,0.0,20.35,30.58],\"type\":\"scatter\"},{\"name\":\"d_test\",\"x\":[\"Linear Regression\",\"Support Vector Machines\",\"Linear SVR\",\"MLPRegressor\",\"Stochastic Gradient Decent\",\"Decision Tree Regressor\",\"Random Forest\",\"GradientBoostingRegressor\",\"RidgeRegressor\",\"XGBoost\",\"LightGBM\",\"BaggingRegressor\",\"ExtraTreesRegressor\",\"AdaBoostRegressor\",\"VotingRegressor\"],\"y\":[42.93,36.2,36.12,31.12,43.0,42.79,15.58,11.93,28.96,16.5,43.05,11.68,13.77,30.02,42.97],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"title\":{\"text\":\"Relative errors for 15 popular models for train and test datasets\"},\"xaxis\":{\"title\":{\"text\":\"Models\"}},\"yaxis\":{\"title\":{\"text\":\"Relative error, %\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('ff075f75-921d-4fee-b923-0aef081c6f58');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot with plotly dark theme\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=models['Model'], y=models['d_train'], name='d_train'))\n",
    "fig.add_trace(go.Scatter(x=models['Model'], y=models['d_test'], name='d_test'))\n",
    "fig.update_layout(title='Relative errors for 15 popular models for train and test datasets',\n",
    "                   xaxis_title='Models',\n",
    "                   yaxis_title='Relative error, %')\n",
    "fig.update_layout(template='plotly_dark')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "rmse_train",
         "x": [
          "Linear Regression",
          "Support Vector Machines",
          "Linear SVR",
          "MLPRegressor",
          "Stochastic Gradient Decent",
          "Decision Tree Regressor",
          "Random Forest",
          "GradientBoostingRegressor",
          "RidgeRegressor",
          "XGBoost",
          "LightGBM",
          "BaggingRegressor",
          "ExtraTreesRegressor",
          "AdaBoostRegressor",
          "VotingRegressor"
         ],
         "y": [
          187.52,
          366.3,
          205.9,
          157.11,
          187.57,
          276.88,
          74.38,
          8.69,
          130.32,
          0.0,
          188.83,
          77.29,
          0.0,
          102.38,
          187.72
         ],
         "type": "scatter"
        },
        {
         "name": "rmse_test",
         "x": [
          "Linear Regression",
          "Support Vector Machines",
          "Linear SVR",
          "MLPRegressor",
          "Stochastic Gradient Decent",
          "Decision Tree Regressor",
          "Random Forest",
          "GradientBoostingRegressor",
          "RidgeRegressor",
          "XGBoost",
          "LightGBM",
          "BaggingRegressor",
          "ExtraTreesRegressor",
          "AdaBoostRegressor",
          "VotingRegressor"
         ],
         "y": [
          214.93,
          304.66,
          202.06,
          175.7,
          215.53,
          303.32,
          92.79,
          77.93,
          146.53,
          111.35,
          216.04,
          72.33,
          93.27,
          140.84,
          215.22
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "bgcolor": "rgb(17,17,17)",
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "rgb(17,17,17)",
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "subunitcolor": "#506784",
           "showland": true,
           "showlakes": true,
           "lakecolor": "rgb(17,17,17)"
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "borderwidth": 1,
           "bordercolor": "rgb(17,17,17)",
           "tickwidth": 0
          },
          "mapbox": {
           "style": "dark"
          }
         }
        },
        "title": {
         "text": "RMSE for 15 popular models for train and test datasets"
        },
        "xaxis": {
         "title": {
          "text": "Models"
         }
        },
        "yaxis": {
         "title": {
          "text": "RMSE, %"
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"e7bdcb1d-00d7-41f3-b0d2-58f43971da1a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e7bdcb1d-00d7-41f3-b0d2-58f43971da1a\")) {                    Plotly.newPlot(                        \"e7bdcb1d-00d7-41f3-b0d2-58f43971da1a\",                        [{\"name\":\"rmse_train\",\"x\":[\"Linear Regression\",\"Support Vector Machines\",\"Linear SVR\",\"MLPRegressor\",\"Stochastic Gradient Decent\",\"Decision Tree Regressor\",\"Random Forest\",\"GradientBoostingRegressor\",\"RidgeRegressor\",\"XGBoost\",\"LightGBM\",\"BaggingRegressor\",\"ExtraTreesRegressor\",\"AdaBoostRegressor\",\"VotingRegressor\"],\"y\":[187.52,366.3,205.9,157.11,187.57,276.88,74.38,8.69,130.32,0.0,188.83,77.29,0.0,102.38,187.72],\"type\":\"scatter\"},{\"name\":\"rmse_test\",\"x\":[\"Linear Regression\",\"Support Vector Machines\",\"Linear SVR\",\"MLPRegressor\",\"Stochastic Gradient Decent\",\"Decision Tree Regressor\",\"Random Forest\",\"GradientBoostingRegressor\",\"RidgeRegressor\",\"XGBoost\",\"LightGBM\",\"BaggingRegressor\",\"ExtraTreesRegressor\",\"AdaBoostRegressor\",\"VotingRegressor\"],\"y\":[214.93,304.66,202.06,175.7,215.53,303.32,92.79,77.93,146.53,111.35,216.04,72.33,93.27,140.84,215.22],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"title\":{\"text\":\"RMSE for 15 popular models for train and test datasets\"},\"xaxis\":{\"title\":{\"text\":\"Models\"}},\"yaxis\":{\"title\":{\"text\":\"RMSE, %\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('e7bdcb1d-00d7-41f3-b0d2-58f43971da1a');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot with plotly dark theme\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=models['Model'], y=models['rmse_train'], name='rmse_train'))\n",
    "fig.add_trace(go.Scatter(x=models['Model'], y=models['rmse_test'], name='rmse_test'))\n",
    "fig.update_layout(title='RMSE for 15 popular models for train and test datasets',\n",
    "                   xaxis_title='Models',\n",
    "                   yaxis_title='RMSE, %')\n",
    "fig.update_layout(template='plotly_dark')\n",
    "fig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "mae_train",
         "x": [
          "Linear Regression",
          "Support Vector Machines",
          "Linear SVR",
          "MLPRegressor",
          "Stochastic Gradient Decent",
          "Decision Tree Regressor",
          "Random Forest",
          "GradientBoostingRegressor",
          "RidgeRegressor",
          "XGBoost",
          "LightGBM",
          "BaggingRegressor",
          "ExtraTreesRegressor",
          "AdaBoostRegressor",
          "VotingRegressor"
         ],
         "y": [
          126.29,
          129.99,
          114.9,
          107.14,
          126.67,
          127.94,
          30.94,
          5.96,
          70.55,
          0.0,
          127.02,
          28.49,
          0.0,
          84.28,
          126.63
         ],
         "type": "scatter"
        },
        {
         "name": "mae_test",
         "x": [
          "Linear Regression",
          "Support Vector Machines",
          "Linear SVR",
          "MLPRegressor",
          "Stochastic Gradient Decent",
          "Decision Tree Regressor",
          "Random Forest",
          "GradientBoostingRegressor",
          "RidgeRegressor",
          "XGBoost",
          "LightGBM",
          "BaggingRegressor",
          "ExtraTreesRegressor",
          "AdaBoostRegressor",
          "VotingRegressor"
         ],
         "y": [
          164.57,
          138.75,
          138.46,
          119.3,
          164.83,
          164.03,
          59.71,
          45.74,
          111.02,
          63.24,
          165.03,
          44.79,
          52.77,
          115.09,
          164.71
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "bgcolor": "rgb(17,17,17)",
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "rgb(17,17,17)",
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "subunitcolor": "#506784",
           "showland": true,
           "showlakes": true,
           "lakecolor": "rgb(17,17,17)"
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "borderwidth": 1,
           "bordercolor": "rgb(17,17,17)",
           "tickwidth": 0
          },
          "mapbox": {
           "style": "dark"
          }
         }
        },
        "title": {
         "text": "MAE for 15 popular models for train and test datasets"
        },
        "xaxis": {
         "title": {
          "text": "Models"
         }
        },
        "yaxis": {
         "title": {
          "text": "MAE, %"
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"96fc273c-65dd-403e-8050-87f6d4eaa7fa\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"96fc273c-65dd-403e-8050-87f6d4eaa7fa\")) {                    Plotly.newPlot(                        \"96fc273c-65dd-403e-8050-87f6d4eaa7fa\",                        [{\"name\":\"mae_train\",\"x\":[\"Linear Regression\",\"Support Vector Machines\",\"Linear SVR\",\"MLPRegressor\",\"Stochastic Gradient Decent\",\"Decision Tree Regressor\",\"Random Forest\",\"GradientBoostingRegressor\",\"RidgeRegressor\",\"XGBoost\",\"LightGBM\",\"BaggingRegressor\",\"ExtraTreesRegressor\",\"AdaBoostRegressor\",\"VotingRegressor\"],\"y\":[126.29,129.99,114.9,107.14,126.67,127.94,30.94,5.96,70.55,0.0,127.02,28.49,0.0,84.28,126.63],\"type\":\"scatter\"},{\"name\":\"mae_test\",\"x\":[\"Linear Regression\",\"Support Vector Machines\",\"Linear SVR\",\"MLPRegressor\",\"Stochastic Gradient Decent\",\"Decision Tree Regressor\",\"Random Forest\",\"GradientBoostingRegressor\",\"RidgeRegressor\",\"XGBoost\",\"LightGBM\",\"BaggingRegressor\",\"ExtraTreesRegressor\",\"AdaBoostRegressor\",\"VotingRegressor\"],\"y\":[164.57,138.75,138.46,119.3,164.83,164.03,59.71,45.74,111.02,63.24,165.03,44.79,52.77,115.09,164.71],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"bgcolor\":\"rgb(17,17,17)\",\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"rgb(17,17,17)\",\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"subunitcolor\":\"#506784\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"rgb(17,17,17)\"},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"borderwidth\":1,\"bordercolor\":\"rgb(17,17,17)\",\"tickwidth\":0},\"mapbox\":{\"style\":\"dark\"}}},\"title\":{\"text\":\"MAE for 15 popular models for train and test datasets\"},\"xaxis\":{\"title\":{\"text\":\"Models\"}},\"yaxis\":{\"title\":{\"text\":\"MAE, %\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('96fc273c-65dd-403e-8050-87f6d4eaa7fa');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot with plotly dark theme\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=models['Model'], y=models['mae_train'], name='mae_train'))\n",
    "fig.add_trace(go.Scatter(x=models['Model'], y=models['mae_test'], name='mae_test'))\n",
    "fig.update_layout(title='MAE for 15 popular models for train and test datasets',\n",
    "                   xaxis_title='Models',\n",
    "                   yaxis_title='MAE, %')\n",
    "fig.update_layout(template='plotly_dark')\n",
    "fig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Model  r2_train  r2_test  d_train  d_test  \\\n0            Linear Regression     86.53    82.07    30.50   42.93   \n1      Support Vector Machines     48.61    63.97    31.39   36.20   \n2                   Linear SVR     83.76    84.15    27.75   36.12   \n3                 MLPRegressor     90.55    88.02    25.88   31.12   \n4   Stochastic Gradient Decent     86.53    81.97    30.59   43.00   \n5      Decision Tree Regressor     70.64    64.29    30.90   42.79   \n6                Random Forest     97.88    96.66     7.47   15.58   \n7    GradientBoostingRegressor     99.97    97.64     1.44   11.93   \n8               RidgeRegressor     93.50    91.67    17.04   28.96   \n9                      XGBoost    100.00    95.19     0.00   16.50   \n10                    LightGBM     86.34    81.88    30.68   43.05   \n11            BaggingRegressor     97.71    97.97     6.88   11.68   \n12         ExtraTreesRegressor    100.00    96.62     0.00   13.77   \n13           AdaBoostRegressor     95.99    92.30    20.35   30.02   \n14             VotingRegressor     86.50    82.02    30.58   42.97   \n\n    rmse_train  rmse_test  mae_train  mae_test  \n0       187.52     214.93     126.29    164.57  \n1       366.30     304.66     129.99    138.75  \n2       205.90     202.06     114.90    138.46  \n3       157.11     175.70     107.14    119.30  \n4       187.57     215.53     126.67    164.83  \n5       276.88     303.32     127.94    164.03  \n6        74.38      92.79      30.94     59.71  \n7         8.69      77.93       5.96     45.74  \n8       130.32     146.53      70.55    111.02  \n9         0.00     111.35       0.00     63.24  \n10      188.83     216.04     127.02    165.03  \n11       77.29      72.33      28.49     44.79  \n12        0.00      93.27       0.00     52.77  \n13      102.38     140.84      84.28    115.09  \n14      187.72     215.22     126.63    164.71  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>r2_train</th>\n      <th>r2_test</th>\n      <th>d_train</th>\n      <th>d_test</th>\n      <th>rmse_train</th>\n      <th>rmse_test</th>\n      <th>mae_train</th>\n      <th>mae_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression</td>\n      <td>86.53</td>\n      <td>82.07</td>\n      <td>30.50</td>\n      <td>42.93</td>\n      <td>187.52</td>\n      <td>214.93</td>\n      <td>126.29</td>\n      <td>164.57</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Support Vector Machines</td>\n      <td>48.61</td>\n      <td>63.97</td>\n      <td>31.39</td>\n      <td>36.20</td>\n      <td>366.30</td>\n      <td>304.66</td>\n      <td>129.99</td>\n      <td>138.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Linear SVR</td>\n      <td>83.76</td>\n      <td>84.15</td>\n      <td>27.75</td>\n      <td>36.12</td>\n      <td>205.90</td>\n      <td>202.06</td>\n      <td>114.90</td>\n      <td>138.46</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MLPRegressor</td>\n      <td>90.55</td>\n      <td>88.02</td>\n      <td>25.88</td>\n      <td>31.12</td>\n      <td>157.11</td>\n      <td>175.70</td>\n      <td>107.14</td>\n      <td>119.30</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Stochastic Gradient Decent</td>\n      <td>86.53</td>\n      <td>81.97</td>\n      <td>30.59</td>\n      <td>43.00</td>\n      <td>187.57</td>\n      <td>215.53</td>\n      <td>126.67</td>\n      <td>164.83</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Decision Tree Regressor</td>\n      <td>70.64</td>\n      <td>64.29</td>\n      <td>30.90</td>\n      <td>42.79</td>\n      <td>276.88</td>\n      <td>303.32</td>\n      <td>127.94</td>\n      <td>164.03</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Random Forest</td>\n      <td>97.88</td>\n      <td>96.66</td>\n      <td>7.47</td>\n      <td>15.58</td>\n      <td>74.38</td>\n      <td>92.79</td>\n      <td>30.94</td>\n      <td>59.71</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>GradientBoostingRegressor</td>\n      <td>99.97</td>\n      <td>97.64</td>\n      <td>1.44</td>\n      <td>11.93</td>\n      <td>8.69</td>\n      <td>77.93</td>\n      <td>5.96</td>\n      <td>45.74</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RidgeRegressor</td>\n      <td>93.50</td>\n      <td>91.67</td>\n      <td>17.04</td>\n      <td>28.96</td>\n      <td>130.32</td>\n      <td>146.53</td>\n      <td>70.55</td>\n      <td>111.02</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>XGBoost</td>\n      <td>100.00</td>\n      <td>95.19</td>\n      <td>0.00</td>\n      <td>16.50</td>\n      <td>0.00</td>\n      <td>111.35</td>\n      <td>0.00</td>\n      <td>63.24</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBM</td>\n      <td>86.34</td>\n      <td>81.88</td>\n      <td>30.68</td>\n      <td>43.05</td>\n      <td>188.83</td>\n      <td>216.04</td>\n      <td>127.02</td>\n      <td>165.03</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>BaggingRegressor</td>\n      <td>97.71</td>\n      <td>97.97</td>\n      <td>6.88</td>\n      <td>11.68</td>\n      <td>77.29</td>\n      <td>72.33</td>\n      <td>28.49</td>\n      <td>44.79</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ExtraTreesRegressor</td>\n      <td>100.00</td>\n      <td>96.62</td>\n      <td>0.00</td>\n      <td>13.77</td>\n      <td>0.00</td>\n      <td>93.27</td>\n      <td>0.00</td>\n      <td>52.77</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AdaBoostRegressor</td>\n      <td>95.99</td>\n      <td>92.30</td>\n      <td>20.35</td>\n      <td>30.02</td>\n      <td>102.38</td>\n      <td>140.84</td>\n      <td>84.28</td>\n      <td>115.09</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>VotingRegressor</td>\n      <td>86.50</td>\n      <td>82.02</td>\n      <td>30.58</td>\n      <td>42.97</td>\n      <td>187.72</td>\n      <td>215.22</td>\n      <td>126.63</td>\n      <td>164.71</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "['GradientBoostingRegressor',\n 'BaggingRegressor',\n 'ExtraTreesRegressor',\n 'Random Forest',\n 'XGBoost',\n 'AdaBoostRegressor',\n 'RidgeRegressor',\n 'MLPRegressor',\n 'Linear Regression',\n 'Linear SVR',\n 'Stochastic Gradient Decent',\n 'VotingRegressor',\n 'LightGBM',\n 'Decision Tree Regressor',\n 'Support Vector Machines']"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.Model.to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Model  test_ranksum  r2_train_rank  r2_test_rank  \\\n0    GradientBoostingRegressor         39.00           2.00          2.00   \n1             BaggingRegressor         41.00           4.00          1.00   \n2          ExtraTreesRegressor         41.00           1.00          4.00   \n3                Random Forest         43.00           3.00          3.00   \n4                      XGBoost         43.00           1.00          5.00   \n5            AdaBoostRegressor         53.00           5.00          6.00   \n6               RidgeRegressor         57.00           6.00          7.00   \n7                 MLPRegressor         61.00           7.00          8.00   \n8            Linear Regression         67.00           8.00         10.00   \n9                   Linear SVR         72.00          11.00          9.00   \n10  Stochastic Gradient Decent         72.00           8.00         12.00   \n11             VotingRegressor         72.00           9.00         11.00   \n12                    LightGBM         78.00          10.00         13.00   \n13     Decision Tree Regressor         84.00          12.00         14.00   \n14     Support Vector Machines         88.00          13.00         15.00   \n\n    d_train_rank  d_test_rank  rmse_train_rank  rmse_test_rank  \\\n0          13.00        14.00             2.00            2.00   \n1          12.00        15.00             4.00            1.00   \n2          14.00        13.00             1.00            4.00   \n3          11.00        12.00             3.00            3.00   \n4          14.00        11.00             1.00            5.00   \n5           9.00         9.00             5.00            6.00   \n6          10.00        10.00             6.00            7.00   \n7           8.00         8.00             7.00            8.00   \n8           6.00         4.00             8.00           10.00   \n9           7.00         7.00            12.00            9.00   \n10          4.00         2.00             9.00           12.00   \n11          5.00         3.00            10.00           11.00   \n12          3.00         1.00            11.00           13.00   \n13          2.00         5.00            13.00           14.00   \n14          1.00         6.00            14.00           15.00   \n\n    mae_train_rank  mae_test_rank  \n0             2.00           2.00  \n1             3.00           1.00  \n2             1.00           3.00  \n3             4.00           4.00  \n4             1.00           5.00  \n5             6.00           7.00  \n6             5.00           6.00  \n7             7.00           8.00  \n8             9.00          12.00  \n9             8.00           9.00  \n10           11.00          14.00  \n11           10.00          13.00  \n12           12.00          15.00  \n13           13.00          11.00  \n14           14.00          10.00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>test_ranksum</th>\n      <th>r2_train_rank</th>\n      <th>r2_test_rank</th>\n      <th>d_train_rank</th>\n      <th>d_test_rank</th>\n      <th>rmse_train_rank</th>\n      <th>rmse_test_rank</th>\n      <th>mae_train_rank</th>\n      <th>mae_test_rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GradientBoostingRegressor</td>\n      <td>39.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>13.00</td>\n      <td>14.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BaggingRegressor</td>\n      <td>41.00</td>\n      <td>4.00</td>\n      <td>1.00</td>\n      <td>12.00</td>\n      <td>15.00</td>\n      <td>4.00</td>\n      <td>1.00</td>\n      <td>3.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ExtraTreesRegressor</td>\n      <td>41.00</td>\n      <td>1.00</td>\n      <td>4.00</td>\n      <td>14.00</td>\n      <td>13.00</td>\n      <td>1.00</td>\n      <td>4.00</td>\n      <td>1.00</td>\n      <td>3.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest</td>\n      <td>43.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>11.00</td>\n      <td>12.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XGBoost</td>\n      <td>43.00</td>\n      <td>1.00</td>\n      <td>5.00</td>\n      <td>14.00</td>\n      <td>11.00</td>\n      <td>1.00</td>\n      <td>5.00</td>\n      <td>1.00</td>\n      <td>5.00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AdaBoostRegressor</td>\n      <td>53.00</td>\n      <td>5.00</td>\n      <td>6.00</td>\n      <td>9.00</td>\n      <td>9.00</td>\n      <td>5.00</td>\n      <td>6.00</td>\n      <td>6.00</td>\n      <td>7.00</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RidgeRegressor</td>\n      <td>57.00</td>\n      <td>6.00</td>\n      <td>7.00</td>\n      <td>10.00</td>\n      <td>10.00</td>\n      <td>6.00</td>\n      <td>7.00</td>\n      <td>5.00</td>\n      <td>6.00</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>MLPRegressor</td>\n      <td>61.00</td>\n      <td>7.00</td>\n      <td>8.00</td>\n      <td>8.00</td>\n      <td>8.00</td>\n      <td>7.00</td>\n      <td>8.00</td>\n      <td>7.00</td>\n      <td>8.00</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Linear Regression</td>\n      <td>67.00</td>\n      <td>8.00</td>\n      <td>10.00</td>\n      <td>6.00</td>\n      <td>4.00</td>\n      <td>8.00</td>\n      <td>10.00</td>\n      <td>9.00</td>\n      <td>12.00</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Linear SVR</td>\n      <td>72.00</td>\n      <td>11.00</td>\n      <td>9.00</td>\n      <td>7.00</td>\n      <td>7.00</td>\n      <td>12.00</td>\n      <td>9.00</td>\n      <td>8.00</td>\n      <td>9.00</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Stochastic Gradient Decent</td>\n      <td>72.00</td>\n      <td>8.00</td>\n      <td>12.00</td>\n      <td>4.00</td>\n      <td>2.00</td>\n      <td>9.00</td>\n      <td>12.00</td>\n      <td>11.00</td>\n      <td>14.00</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>VotingRegressor</td>\n      <td>72.00</td>\n      <td>9.00</td>\n      <td>11.00</td>\n      <td>5.00</td>\n      <td>3.00</td>\n      <td>10.00</td>\n      <td>11.00</td>\n      <td>10.00</td>\n      <td>13.00</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>LightGBM</td>\n      <td>78.00</td>\n      <td>10.00</td>\n      <td>13.00</td>\n      <td>3.00</td>\n      <td>1.00</td>\n      <td>11.00</td>\n      <td>13.00</td>\n      <td>12.00</td>\n      <td>15.00</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Decision Tree Regressor</td>\n      <td>84.00</td>\n      <td>12.00</td>\n      <td>14.00</td>\n      <td>2.00</td>\n      <td>5.00</td>\n      <td>13.00</td>\n      <td>14.00</td>\n      <td>13.00</td>\n      <td>11.00</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Support Vector Machines</td>\n      <td>88.00</td>\n      <td>13.00</td>\n      <td>15.00</td>\n      <td>1.00</td>\n      <td>6.00</td>\n      <td>14.00</td>\n      <td>15.00</td>\n      <td>14.00</td>\n      <td>10.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_models = len(models)\n",
    "models['r2_train_rank'] = models['r2_train'].rank(method='dense', ascending=False)\n",
    "models['r2_test_rank'] = models['r2_test'].rank(method='dense', ascending=False)\n",
    "models['d_train_rank'] = models['d_train'].rank(method='dense', ascending=False)\n",
    "models['d_test_rank'] = models['d_test'].rank(method='dense', ascending=False)\n",
    "models['rmse_train_rank'] = models['rmse_train'].rank(method='dense')\n",
    "models['rmse_test_rank'] = models['rmse_test'].rank(method='dense')\n",
    "models['mae_train_rank'] = models['mae_train'].rank(method='dense')\n",
    "models['mae_test_rank'] = models['mae_test'].rank(method='dense')\n",
    "models['test_ranksum'] = (models['r2_train_rank'] + models['r2_test_rank'] +\n",
    "                          models['d_train_rank'] + models['d_test_rank'] +\n",
    "                          models['rmse_train_rank'] + models['rmse_test_rank'] +\n",
    "                          models['mae_train_rank'] + models['mae_test_rank'])\n",
    "models = models.sort_values(by=['test_ranksum'], ascending=True)\n",
    "models = models.sort_values(by=['test_ranksum'], ascending=True)\n",
    "models = models.reset_index(drop=True)\n",
    "models_rank = models[['Model', 'test_ranksum', 'r2_train_rank', 'r2_test_rank', 'd_train_rank', 'd_test_rank', 'rmse_train_rank', 'rmse_test_rank', 'mae_train_rank', 'mae_test_rank']]\n",
    "models_rank"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- The best performing model is ----- \n",
      "\n",
      " The GradientBoostingRegressor \n",
      " \n",
      " r2_train = 99.97 r2_test = 97.64 \n",
      " d_train = 1.44 d_test = 11.93 \n",
      " rmse_train = 8.69 rmse_test = 77.93 \n",
      " mae_train = 5.96 mae_test = 45.74\n",
      "\n",
      "----- The second best performing model is ----- \n",
      "\n",
      " The BaggingRegressor \n",
      " \n",
      " r2_train = 97.71 r2_test = 97.97 \n",
      " d_train = 6.88 d_test = 11.68 \n",
      " rmse_train = 77.29 rmse_test = 72.33 \n",
      " mae_train = 28.49 mae_test = 44.79\n",
      "\n",
      "----- The third best performing model is ----- \n",
      "\n",
      " The ExtraTreesRegressor \n",
      " \n",
      " r2_train = 100.0 r2_test = 96.62 \n",
      " d_train = 0.0 d_test = 13.77 \n",
      " rmse_train = 0.0 rmse_test = 93.27 \n",
      " mae_train = 0.0 mae_test = 52.77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The three overall best performing models\n",
    "print(f'----- The best performing model is ----- \\n\\n The {models.Model[0]} \\n \\n r2_train = {models.r2_train[0]} r2_test = {models.r2_test[0]} \\n d_train = {models.d_train[0]} d_test = {models.d_test[0]} \\n rmse_train = {models.rmse_train[0]} rmse_test = {models.rmse_test[0]} \\n mae_train = {models.mae_train[0]} mae_test = {models.mae_test[0]}\\n')\n",
    "\n",
    "print(f'----- The second best performing model is ----- \\n\\n The {models.Model[1]} \\n \\n r2_train = {models.r2_train[1]} r2_test = {models.r2_test[1]} \\n d_train = {models.d_train[1]} d_test = {models.d_test[1]} \\n rmse_train = {models.rmse_train[1]} rmse_test = {models.rmse_test[1]} \\n mae_train = {models.mae_train[1]} mae_test = {models.mae_test[1]}\\n')\n",
    "\n",
    "print(f'----- The third best performing model is ----- \\n\\n The {models.Model[2]} \\n \\n r2_train = {models.r2_train[2]} r2_test = {models.r2_test[2]} \\n d_train = {models.d_train[2]} d_test = {models.d_test[2]} \\n rmse_train = {models.rmse_train[2]} rmse_test = {models.rmse_test[2]} \\n mae_train = {models.mae_train[2]} mae_test = {models.mae_test[2]}\\n')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 61 entries, 223 to 92\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype\n",
      "---  ------         --------------  -----\n",
      " 0   Car_Name       61 non-null     int64\n",
      " 1   Year           61 non-null     int64\n",
      " 2   Present_Price  61 non-null     int64\n",
      " 3   Kms_Driven     61 non-null     int64\n",
      " 4   Fuel_Type      61 non-null     int64\n",
      " 5   Seller_Type    61 non-null     int64\n",
      " 6   Transmission   61 non-null     int64\n",
      " 7   Owner          61 non-null     int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 4.3 KB\n"
     ]
    }
   ],
   "source": [
    "test0.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "     Car_Name  Year  Present_Price  Kms_Driven  Fuel_Type  Seller_Type  \\\n223        94   115              9       61381          1            0   \n150        52   111              0        6000          2            1   \n226        82   115              5       24678          2            0   \n296        69   116             11       33988          1            0   \n52         86   117             19       15000          1            0   \n..        ...   ...            ...         ...        ...          ...   \n137        20   113              0       16000          2            1   \n227        83   111              4       57000          2            0   \n26         92   113              5       55138          2            0   \n106        40   114              3       16500          2            1   \n92         86   105             13       75000          2            0   \n\n     Transmission  Owner  \n223             1      0  \n150             1      0  \n226             1      0  \n296             1      0  \n52              0      0  \n..            ...    ...  \n137             1      0  \n227             1      0  \n26              1      0  \n106             1      1  \n92              1      0  \n\n[61 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Car_Name</th>\n      <th>Year</th>\n      <th>Present_Price</th>\n      <th>Kms_Driven</th>\n      <th>Fuel_Type</th>\n      <th>Seller_Type</th>\n      <th>Transmission</th>\n      <th>Owner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>223</th>\n      <td>94</td>\n      <td>115</td>\n      <td>9</td>\n      <td>61381</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>52</td>\n      <td>111</td>\n      <td>0</td>\n      <td>6000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>82</td>\n      <td>115</td>\n      <td>5</td>\n      <td>24678</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>69</td>\n      <td>116</td>\n      <td>11</td>\n      <td>33988</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>86</td>\n      <td>117</td>\n      <td>19</td>\n      <td>15000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>20</td>\n      <td>113</td>\n      <td>0</td>\n      <td>16000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <td>83</td>\n      <td>111</td>\n      <td>4</td>\n      <td>57000</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>92</td>\n      <td>113</td>\n      <td>5</td>\n      <td>55138</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>40</td>\n      <td>114</td>\n      <td>3</td>\n      <td>16500</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>86</td>\n      <td>105</td>\n      <td>13</td>\n      <td>75000</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>61 rows  8 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "#For models from Sklearn\n",
    "testn = pd.DataFrame(scaler.transform(test0), columns = test0.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 6.67129475, -0.8974948 ,  3.73727157])"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Regression model for basic train\n",
    "linreg.fit(train0, train_target0)\n",
    "linreg.predict(testn)[:3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 6.75784942, -0.76673981,  3.80798505])"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ridge Regressor model for basic train\n",
    "ridge.fit(train0, train_target0)\n",
    "ridge.predict(testn)[:3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# Function to predict with Gradient Boosting Regressor model\n",
    "def predict_gbr(train, train_target, test):\n",
    "    # Initiate the model\n",
    "    gbr = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.05, max_depth=4, max_features='sqrt',\n",
    "                                    min_samples_leaf=15, min_samples_split=10, loss='huber', random_state=42)\n",
    "    gbr.fit(train, train_target)\n",
    "    gbr_pred = gbr.predict(test)\n",
    "    return gbr_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Function to predict with Bagging Regressor model\n",
    "def predict_br(train, train_target, test):\n",
    "    # Initiate the model\n",
    "    br = BaggingRegressor(n_estimators=1000, max_samples=0.5, max_features=0.5, random_state=42)\n",
    "    br.fit(train, train_target)\n",
    "    br_pred = br.predict(test)\n",
    "    return br_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# Function to predict with Extra Trees Regressor model\n",
    "def predict_etr(train, train_target, test):\n",
    "    # Initiate the model\n",
    "    etr = ExtraTreesRegressor(n_estimators=1000, max_depth=6, max_features='sqrt', min_samples_leaf=15,\n",
    "                              min_samples_split=10, random_state=42)\n",
    "    etr.fit(train, train_target)\n",
    "    etr_pred = etr.predict(test)\n",
    "    return etr_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "     Actual  predict_br  predict_gbr  predict_etr\n223       8        6.18         6.45         5.86\n150       0        0.19         0.16         1.78\n226       5        4.62         3.67         4.75\n296       9        7.86         8.44         6.16\n52       18       15.55        22.60         7.98\n..      ...         ...          ...          ...\n137       0        0.33         0.15         1.51\n227       2        2.75         1.92         4.35\n26        4        3.42         2.75         4.47\n106       1        1.40         1.26         1.81\n92        3        4.42         4.19         4.77\n\n[61 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual</th>\n      <th>predict_br</th>\n      <th>predict_gbr</th>\n      <th>predict_etr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>223</th>\n      <td>8</td>\n      <td>6.18</td>\n      <td>6.45</td>\n      <td>5.86</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>0</td>\n      <td>0.19</td>\n      <td>0.16</td>\n      <td>1.78</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>5</td>\n      <td>4.62</td>\n      <td>3.67</td>\n      <td>4.75</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>9</td>\n      <td>7.86</td>\n      <td>8.44</td>\n      <td>6.16</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>18</td>\n      <td>15.55</td>\n      <td>22.60</td>\n      <td>7.98</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>0</td>\n      <td>0.33</td>\n      <td>0.15</td>\n      <td>1.51</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <td>2</td>\n      <td>2.75</td>\n      <td>1.92</td>\n      <td>4.35</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>4</td>\n      <td>3.42</td>\n      <td>2.75</td>\n      <td>4.47</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>1</td>\n      <td>1.40</td>\n      <td>1.26</td>\n      <td>1.81</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>3</td>\n      <td>4.42</td>\n      <td>4.19</td>\n      <td>4.77</td>\n    </tr>\n  </tbody>\n</table>\n<p>61 rows  4 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame({'Actual': test_target0, 'predict_br': predict_br(train0, train_target0, testn),\n",
    "                        'predict_gbr': predict_gbr(train0, train_target0, testn),\n",
    "                        'predict_etr': predict_etr(train0, train_target0, testn)})\n",
    "df_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Thank you very much for your attention. We present the three best performing models: Gradient Boosting Regressor, Bagging Regressor and Extra Trees Regressor. We will use the Gradient Boosting Regressor model for further predictions. The relevant statistics for the model are presented below.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
